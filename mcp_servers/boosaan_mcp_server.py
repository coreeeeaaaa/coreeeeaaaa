#!/usr/bin/env python3
"""
BOOSAAN ULTIMATE MCP ì„œë²„ v7.0 (Google CTOê¸‰ í”„ë ˆì„ì›Œí¬)
- 4ê°œ í•µì‹¬ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©
- ë©”íƒ€ì¸ì§€ ì—”ì§„ + ê³„ì¸µì  ë§¥ë½ ê´€ë¦¬ + ìƒŒë“œë°•ìŠ¤ ê´€ë¦¬ + ì‚¬ê³  ê³ ë„í™”
- 5ë‹¨ê³„ ìœ„í—˜ í‰ê°€ ì‹œìŠ¤í…œ ë‚´ì¥
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
"""

import json
import sys
import os
import asyncio
import logging
import time
import threading
import uuid
import hashlib
import pickle
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime, timezone, timedelta
import sqlite3

# SECURITY: ì•ˆì „í•œ ê²½ë¡œ ê²€ì¦ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent / 'boosaan'))
from secure_path_validator import validate_path, path_validator

# ê¸°ì¡´ êµ¬í˜„ëœ í•µì‹¬ ì‹œìŠ¤í…œë“¤ ì„í¬íŠ¸
sys.path.append(str(Path(__file__).parent))

from boosaan_meta_cognitive_engine import MetaCognitiveEngine, ThinkingStage
from boosaan_context_hierarchy import ContextHierarchyManager, ContextLevel, MemoryType, ContextQuery
from boosaan_sandbox_manager import SandboxManager, SandboxConfig, PermissionLevel, ResourceLimit
from boosaan_thinking_advancement import ThinkingAdvancementEngine, ThinkingTask, ReasoningModel, ThinkingMode, ContextualPriority
from boosaan_work_process_enforcer import WorkProcessEnforcer, WorkInstruction, WorkFeedback, FeedbackType, WorkType
from boosaan_context_document_manager import ContextDocumentManager, UserInstruction, UserIntentionPoint, FeatureSpec, TechnicalBlueprint
from boosaan_port_manager import get_port_manager, get_project_port, register_project
from boosaan_rule_isolation_system import BOOSAANRuleIsolationSystem, IntentionType, RuleType, RuleScope

class BOOSAANUltimateMCPServer:
    def __init__(self):
        self.name = "BOOSAAN ULTIMATE v7.1"
        self.version = "7.1.0"
        
        # í„°ë¯¸ë„ ì„¸ì…˜ ID ìƒì„± ë° ê´€ë¦¬
        self.terminal_id = self._generate_terminal_id()
        self.session_start_time = datetime.now(timezone.utc)
        
        # ì‘ì—… ì¶”ì  ì‹œìŠ¤í…œ
        self.conversation_counter = 0
        self.task_counter = 0
        self.session_db_lock = threading.Lock()
        
        # ë§¥ë½ ì—°ì†ì„±ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
        self.context_memory = {}
        self.last_context_save = time.time()
        
        # ì „ì—­ ì ìš© ëª¨ë“œ ì„¤ì •
        self.global_mode = os.getenv("GLOBAL_BOOSAAN_MODE", "true").lower() == "true"
        self.apply_to_all_agents = os.getenv("APPLY_TO_ALL_AGENTS", "true").lower() == "true" 
        self.force_global = os.getenv("FORCE_GLOBAL_ENFORCEMENT", "true").lower() == "true"
        
        # MCP ì›Œí¬ìŠ¤í˜ì´ìŠ¤ (ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ê²©ë¦¬) - ê²½ë¡œ ê²€ì¦ ì¶”ê°€
        import hashlib
        
        # Claude Code ì¸ìŠ¤í„´ìŠ¤ë³„ ê³ ìœ  ID ìƒì„±
        session_id = os.getenv('CLAUDE_SESSION_ID', 'default')
        process_id = str(os.getpid())
        instance_hash = hashlib.md5(f"{session_id}_{process_id}".encode()).hexdigest()[:8]
        
        if self.global_mode or self.apply_to_all_agents:
            workspace_path = str(Path.home() / '.boosaan' / 'global_workspace' / f'instance_{instance_hash}')
        else:
            workspace_path = str(Path.home() / '.boosaan' / 'ultimate_mcp' / f'instance_{instance_hash}')
        
        # SECURITY: ê²½ë¡œ ê²€ì¦
        if not validate_path(workspace_path):
            raise PermissionError(f"Workspace path not allowed: {workspace_path}")
        
        self.workspace = Path(workspace_path)
        self.workspace.mkdir(parents=True, exist_ok=True)
        
        # í•µì‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.meta_cognitive = MetaCognitiveEngine(str(self.workspace / 'meta_cognitive'))
        self.context_manager = ContextHierarchyManager(str(self.workspace / 'context_hierarchy'))
        self.sandbox_manager = SandboxManager(str(self.workspace / 'sandbox'))
        self.thinking_engine = ThinkingAdvancementEngine(str(self.workspace / 'thinking_advancement'))
        self.work_enforcer = WorkProcessEnforcer(str(self.workspace / 'work_process'))
        self.context_document_manager = ContextDocumentManager(str(self.workspace / 'context_documents'))
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_metrics = {
            "total_requests": 0,
            "successful_operations": 0,
            "blocked_operations": 0,
            "average_response_time": 0.0
        }
        
        # ë¡œê¹… ì„¤ì •
        self.setup_logging()
        
        # í„°ë¯¸ë„ ì„¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_session_database()
        
        # ë§¥ë½ ë³µì› (ì´ì „ í„°ë¯¸ë„ ì„¸ì…˜ì´ ìˆë‹¤ë©´)
        self._restore_context_if_exists()
        
        # í¬íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë¡œê¹… í›„)
        self.port_manager = get_port_manager()
        self.assigned_port = None
        self._initialize_port_allocation()
        
        # ê·œì¹™ ê²©ë¦¬ ë° ì˜ˆì¸¡ì  í”¼ë“œë°± ì‹œìŠ¤í…œ
        self.rule_isolation = BOOSAANRuleIsolationSystem(str(self.workspace / 'rule_isolation'))
        
        # ë³´ì•ˆ ì„¤ì •
        self.security_level = "MAXIMUM"
        self.auto_risk_assessment = True

    def _generate_terminal_id(self) -> str:
        """í„°ë¯¸ë„ ê³ ìœ  ID ìƒì„± (ì„¸ì…˜ë³„ë¡œ ê³ ìœ í•˜ë©´ì„œë„ ì¬ì‹œì‘ ì‹œ ì—°ì†ì„± ìœ ì§€)"""
        # í„°ë¯¸ë„ í™˜ê²½ ì •ë³´ ê¸°ë°˜ ID ìƒì„±
        terminal_env = {
            'pid': os.getpid(),
            'ppid': os.getppid(),
            'user': os.getenv('USER', 'unknown'),
            'shell': os.getenv('SHELL', 'unknown'),
            'term': os.getenv('TERM', 'unknown'),
            'pwd': os.getcwd()
        }
        
        # í™˜ê²½ ì •ë³´ë¥¼ í•´ì‹œí™”í•˜ì—¬ ì•ˆì •ì ì¸ í„°ë¯¸ë„ ID ìƒì„±
        env_string = json.dumps(terminal_env, sort_keys=True)
        terminal_hash = hashlib.sha256(env_string.encode()).hexdigest()[:12]
        
        # ë‚ ì§œ ê¸°ë°˜ ì ‘ë‘ì‚¬ë¡œ ì„¸ì…˜ êµ¬ë¶„
        date_prefix = datetime.now().strftime('%Y%m%d')
        
        return f"TERM_{date_prefix}_{terminal_hash}"

    def _init_session_database(self):
        """í„°ë¯¸ë„ ì„¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.session_db_path = self.workspace / f'terminal_sessions_{self.terminal_id}.db'
        
        with sqlite3.connect(str(self.session_db_path)) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    conversation_id TEXT UNIQUE,
                    terminal_id TEXT,
                    timestamp TEXT,
                    request_data TEXT,
                    response_data TEXT,
                    task_id TEXT,
                    status TEXT
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS context_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    terminal_id TEXT,
                    snapshot_time TEXT,
                    context_data BLOB,
                    metadata TEXT
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS task_tracking (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    task_id TEXT UNIQUE,
                    terminal_id TEXT,
                    created_at TEXT,
                    updated_at TEXT,
                    task_type TEXT,
                    status TEXT,
                    progress_data TEXT
                )
            ''')
        
        # í˜„ì¬ ì„¸ì…˜ ì •ë³´ ì €ì¥
        self._save_session_start()

    def _save_session_start(self):
        """ì„¸ì…˜ ì‹œì‘ ì •ë³´ ì €ì¥"""
        with sqlite3.connect(str(self.session_db_path)) as conn:
            session_info = {
                'terminal_id': self.terminal_id,
                'start_time': self.session_start_time.isoformat(),
                'workspace': str(self.workspace),
                'version': self.version
            }
            
            conn.execute('''
                INSERT OR REPLACE INTO context_snapshots 
                (terminal_id, snapshot_time, context_data, metadata)
                VALUES (?, ?, ?, ?)
            ''', (
                self.terminal_id,
                datetime.now(timezone.utc).isoformat(),
                pickle.dumps({}),  # ë¹ˆ ì‹œì‘ ì»¨í…ìŠ¤íŠ¸
                json.dumps(session_info)
            ))

    def _restore_context_if_exists(self):
        """ì´ì „ ì„¸ì…˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë³µì› (ê°™ì€ í„°ë¯¸ë„ ID)"""
        try:
            with sqlite3.connect(str(self.session_db_path)) as conn:
                cursor = conn.execute('''
                    SELECT context_data, metadata, snapshot_time
                    FROM context_snapshots 
                    WHERE terminal_id = ?
                    ORDER BY id DESC LIMIT 1
                ''', (self.terminal_id,))
                
                result = cursor.fetchone()
                if result:
                    context_data, metadata_str, snapshot_time = result
                    metadata = json.loads(metadata_str)
                    
                    # 24ì‹œê°„ ì´ë‚´ì˜ ì„¸ì…˜ë§Œ ë³µì›
                    snapshot_dt = datetime.fromisoformat(snapshot_time.replace('Z', '+00:00'))
                    if (datetime.now(timezone.utc) - snapshot_dt).total_seconds() < 86400:
                        self.context_memory = pickle.loads(context_data)
                        self.logger.info(f"ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë³µì›: {len(self.context_memory)}ê°œ í•­ëª©")
                    else:
                        self.logger.info("24ì‹œê°„ ì´ìƒ ê²½ê³¼í•œ ì„¸ì…˜, ìƒˆë¡œ ì‹œì‘")
                        
        except Exception as e:
            self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ ë³µì› ì‹¤íŒ¨: {e}")

    def setup_logging(self):
        """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì • (í„°ë¯¸ë„ ID í¬í•¨)"""
        log_file = self.workspace / f'boosaan_ultimate_{self.terminal_id}.log'
        logging.basicConfig(
            filename=str(log_file),
            level=logging.INFO,
            format=f'%(asctime)s - BOOSAAN_ULTIMATE[{self.terminal_id}] - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

    def _initialize_port_allocation(self):
        """BOOSAAN Ultimateìš© í¬íŠ¸ í• ë‹¹"""
        try:
            # boosaan í”„ë¡œì íŠ¸ê°€ ì´ë¯¸ ì˜ˆì•½ë˜ì–´ ìˆìœ¼ë¯€ë¡œ í•´ë‹¹ ë²”ìœ„ì—ì„œ í¬íŠ¸ í• ë‹¹
            self.assigned_port = get_project_port("boosaan", "ultimate_mcp_server")
            self.logger.info(f"BOOSAAN Ultimate MCP ì„œë²„ í¬íŠ¸ í• ë‹¹: {self.assigned_port}")
        except Exception as e:
            self.logger.error(f"í¬íŠ¸ í• ë‹¹ ì‹¤íŒ¨: {e}")
            self.assigned_port = 8000  # ê¸°ë³¸ í¬íŠ¸ë¡œ í´ë°±

    async def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """MCP ìš”ì²­ ì²˜ë¦¬ (í„°ë¯¸ë„ ID ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì  í¬í•¨)"""
        start_time = time.time()
        
        # ëŒ€í™” ID ë° ì‘ì—… ID ìƒì„±
        self.conversation_counter += 1
        conversation_id = f"{self.terminal_id}_CONV_{self.conversation_counter:06d}"
        
        method = request.get("method")
        params = request.get("params", {})
        
        # ì‘ì—… íƒ€ì…ì— ë”°ë¼ ì‘ì—… ID ìƒì„±
        task_id = None
        if method == "tools/call":
            self.task_counter += 1
            tool_name = params.get("name", "unknown")
            task_id = f"{self.terminal_id}_TASK_{self.task_counter:06d}_{tool_name}"
        
        # ìš”ì²­ ì¶”ì  ì •ë³´ ìƒì„±
        tracking_info = {
            "conversation_id": conversation_id,
            "task_id": task_id,
            "terminal_id": self.terminal_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "method": method,
            "request_start": start_time
        }
        
        # ë¡œê·¸ì— ì¶”ì  ì •ë³´ ê¸°ë¡
        self.logger.info(f"[{conversation_id}] ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {method} (ì‘ì—…ID: {task_id})")
        
        self.performance_metrics["total_requests"] += 1
        
        try:
            # 1ë‹¨ê³„: ìë™ ìœ„í—˜ í‰ê°€ (ê³¼ë¶€í•˜ ë°©ì§€ í¬í•¨)
            if self.auto_risk_assessment:
                risk_assessment = await self._assess_request_risk(method, params)
                if risk_assessment["total_risk"] >= 35:
                    self.performance_metrics["blocked_operations"] += 1
                    
                    # ì°¨ë‹¨ëœ ìš”ì²­ë„ ì¶”ì 
                    await self._save_conversation_record(
                        conversation_id, task_id, tracking_info, 
                        request, {"status": "BLOCKED", "reason": "ìœ„í—˜ë„ ì„ê³„ê°’ ì´ˆê³¼"}
                    )
                    
                    return {
                        "error": {
                            "code": -32000,
                            "message": f"ìœ„í—˜ë„ ì„ê³„ê°’ ì´ˆê³¼ - ìš”ì²­ ì°¨ë‹¨ [ëŒ€í™”ID: {conversation_id}]",
                            "data": risk_assessment
                        }
                    }
            
            # 2ë‹¨ê³„: ë¬´í•œë£¨í”„ ë°©ì§€ ì²´í¬
            if await self._check_infinite_loop_risk(method, params):
                self.logger.warning(f"[{conversation_id}] ë¬´í•œë£¨í”„ ìœ„í—˜ ê°ì§€ - ìš”ì²­ ì œí•œ")
                return {
                    "error": {
                        "code": -32001,
                        "message": f"ë¬´í•œë£¨í”„ ë°©ì§€ - ìš”ì²­ ì œí•œ [ëŒ€í™”ID: {conversation_id}]"
                    }
                }
            
            # 3ë‹¨ê³„: ë©”ì„œë“œë³„ ì²˜ë¦¬ (ì¶”ì  ì •ë³´ í¬í•¨)
            if method == "initialize":
                response = await self.initialize(params)
            elif method == "tools/list":
                response = await self.list_tools()
            elif method == "tools/call":
                response = await self.call_tool(params, tracking_info)
            elif method == "resources/list":
                response = await self.list_resources()
            elif method == "resources/read":
                response = await self.read_resource(params)
            else:
                response = {"error": {"code": -32601, "message": f"Method not found: {method}"}}
            
            # 4ë‹¨ê³„: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_performance_metrics(response_time, True)
            
            # 5ë‹¨ê³„: ëŒ€í™” ê¸°ë¡ ì €ì¥
            await self._save_conversation_record(conversation_id, task_id, tracking_info, request, response)
            
            # 6ë‹¨ê³„: ë§¥ë½ ìŠ¤ëƒ…ìƒ· (ì£¼ê¸°ì )
            if time.time() - self.last_context_save > 300:  # 5ë¶„ë§ˆë‹¤
                await self._save_context_snapshot()
                self.last_context_save = time.time()
            
            self.performance_metrics["successful_operations"] += 1
            
            # ì‘ë‹µì— ì¶”ì  ì •ë³´ ì¶”ê°€
            if isinstance(response, dict) and "content" in response:
                response["tracking"] = {
                    "conversation_id": conversation_id,
                    "task_id": task_id,
                    "terminal_id": self.terminal_id,
                    "timestamp": tracking_info["timestamp"]
                }
            
            self.logger.info(f"[{conversation_id}] ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: {response_time:.3f}ì´ˆ")
            return response
                
        except Exception as e:
            self.logger.error(f"[{conversation_id}] Request handling error: {e}")
            self._update_performance_metrics(time.time() - start_time, False)
            
            # ì˜¤ë¥˜ë„ ì¶”ì 
            await self._save_conversation_record(
                conversation_id, task_id, tracking_info, 
                request, {"status": "ERROR", "error": str(e)}
            )
            
            return {"error": {"code": -32603, "message": f"[{conversation_id}] {str(e)}"}}

    async def _assess_request_risk(self, method: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """ìš”ì²­ ìœ„í—˜ë„ í‰ê°€ (Google CTOê¸‰ 5ë‹¨ê³„ ì‹œìŠ¤í…œ)"""
        
        risks = {
            "security_risk": self._evaluate_method_security_risk(method, params),
            "functional_risk": self._evaluate_method_functional_risk(method, params),
            "contextual_risk": self._evaluate_method_contextual_risk(method, params),
            "performance_risk": self._evaluate_method_performance_risk(method, params),
            "operational_risk": self._evaluate_method_operational_risk(method, params)
        }
        
        total_risk = sum(risks.values())
        risk_level = "CRITICAL" if total_risk >= 35 else "HIGH" if total_risk >= 25 else "MEDIUM" if total_risk >= 15 else "LOW"
        
        return {
            "individual_risks": risks,
            "total_risk": total_risk,
            "risk_level": risk_level,
            "assessment_time": time.time()
        }

    def _evaluate_method_security_risk(self, method: str, params: Dict[str, Any]) -> int:
        """ë©”ì„œë“œ ë³´ì•ˆ ìœ„í—˜ í‰ê°€"""
        high_risk_methods = ["tools/call", "sandbox_execute", "system_modify"]
        medium_risk_methods = ["resources/read", "context_update"]
        
        if method in high_risk_methods:
            return 8
        elif method in medium_risk_methods:
            return 4
        else:
            return 1

    def _evaluate_method_functional_risk(self, method: str, params: Dict[str, Any]) -> int:
        """ë©”ì„œë“œ ê¸°ëŠ¥ì  ìœ„í—˜ í‰ê°€"""
        if method == "tools/call":
            tool_name = params.get("name", "")
            if "delete" in tool_name or "destroy" in tool_name:
                return 7
            elif "execute" in tool_name:
                return 5
        return 2

    def _evaluate_method_contextual_risk(self, method: str, params: Dict[str, Any]) -> int:
        """ë©”ì„œë“œ ë§¥ë½ì  ìœ„í—˜ í‰ê°€"""
        return 3  # ê¸°ë³¸ê°’

    def _evaluate_method_performance_risk(self, method: str, params: Dict[str, Any]) -> int:
        """ë©”ì„œë“œ ì„±ëŠ¥ ìœ„í—˜ í‰ê°€"""
        if method == "tools/call":
            tool_name = params.get("name", "")
            if "thinking_advancement" in tool_name:
                return 4  # ë†’ì€ CPU ì‚¬ìš©ëŸ‰
        return 2

    def _evaluate_method_operational_risk(self, method: str, params: Dict[str, Any]) -> int:
        """ë©”ì„œë“œ ìš´ì˜ ìœ„í—˜ í‰ê°€"""
        return 2  # ê¸°ë³¸ê°’

    async def initialize(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """MCP ì„œë²„ ì´ˆê¸°í™”"""
        self.logger.info("BOOSAAN ULTIMATE MCP ì„œë²„ ì´ˆê¸°í™”")
        
        return {
            "protocolVersion": "2024-11-05",
            "capabilities": {
                "tools": {},
                "resources": {},
                "logging": {}
            },
            "serverInfo": {
                "name": self.name,
                "version": self.version,
                "description": "Google CTOê¸‰ BOOSAAN 4ëŒ€ í•µì‹¬ ì‹œìŠ¤í…œ í†µí•©"
            }
        }

    async def list_tools(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡"""
        tools = [
            # 1. ë©”íƒ€ì¸ì§€ ë„êµ¬
            {
                "name": "sequential_thinking",
                "description": "5ë‹¨ê³„ Sequential Thinking ì‹¤í–‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "request": {"type": "string"},
                        "context": {"type": "object", "optional": True}
                    },
                    "required": ["request"]
                }
            },
            
            # 2. ë§¥ë½ ê´€ë¦¬ ë„êµ¬
            {
                "name": "create_project_context",
                "description": "ìƒˆ í”„ë¡œì íŠ¸ ë§¥ë½ ìƒì„±",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "project_name": {"type": "string"},
                        "project_path": {"type": "string"},
                        "content": {"type": "object"}
                    },
                    "required": ["project_name", "project_path", "content"]
                }
            },
            
            {
                "name": "update_global_context",
                "description": "ì „ì—­ ë§¥ë½ ì—…ë°ì´íŠ¸",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "content": {"type": "object"}
                    },
                    "required": ["content"]
                }
            },
            
            {
                "name": "query_context",
                "description": "ë§¥ë½ ê²€ìƒ‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query_text": {"type": "string"},
                        "context_level": {"type": "string", "enum": ["ì „ì—­", "í”„ë¡œì íŠ¸", "ì„¸ì…˜", "ì¦‰ì‹œ"]},
                        "relevance_threshold": {"type": "number", "default": 0.5}
                    },
                    "required": ["query_text"]
                }
            },
            
            {
                "name": "execute_forgetting_cycle",
                "description": "8ì°¨ì› ë§ê° ì‚¬ì´í´ ì‹¤í–‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            
            # 3. ìƒŒë“œë°•ìŠ¤ ë„êµ¬
            {
                "name": "create_sandbox",
                "description": "ìƒˆ ìƒŒë“œë°•ìŠ¤ í™˜ê²½ ìƒì„±",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "sandbox_id": {"type": "string"},
                        "project_path": {"type": "string"},
                        "permission_level": {"type": "string", "enum": ["ìƒŒë“œë°•ìŠ¤_ë ˆë²¨", "ì‚¬ìš©ì_ë ˆë²¨"], "default": "ìƒŒë“œë°•ìŠ¤_ë ˆë²¨"},
                        "network_allowed": {"type": "boolean", "default": False},
                        "time_limit": {"type": "integer", "default": 300}
                    },
                    "required": ["sandbox_id", "project_path"]
                }
            },
            
            {
                "name": "execute_in_sandbox",
                "description": "ìƒŒë“œë°•ìŠ¤ ë‚´ì—ì„œ ì•ˆì „í•œ ëª…ë ¹ ì‹¤í–‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "sandbox_id": {"type": "string"},
                        "command": {"type": "string"},
                        "input_data": {"type": "string", "optional": True}
                    },
                    "required": ["sandbox_id", "command"]
                }
            },
            
            {
                "name": "get_sandbox_status",
                "description": "ìƒŒë“œë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "sandbox_id": {"type": "string"}
                    },
                    "required": ["sandbox_id"]
                }
            },
            
            {
                "name": "destroy_sandbox",
                "description": "ìƒŒë“œë°•ìŠ¤ ì™„ì „ ì‚­ì œ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "sandbox_id": {"type": "string"}
                    },
                    "required": ["sandbox_id"]
                }
            },
            
            # 4. ì‚¬ê³  ê³ ë„í™” ë„êµ¬
            {
                "name": "thinking_advancement",
                "description": "ë‹¤ì¤‘ ì¶”ë¡  ëª¨ë¸ ê¸°ë°˜ ê³ ê¸‰ ì‚¬ê³  ì‹¤í–‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "task_content": {"type": "string"},
                        "thinking_mode": {"type": "string", "enum": ["ì‹¬ì¸µ_ì‚¬ê³ ", "ê´‘ë²”ìœ„_ì‚¬ê³ ", "ì§‘ì¤‘_ì‚¬ê³ "], "default": "ì‹¬ì¸µ_ì‚¬ê³ "},
                        "priority": {"type": "string", "enum": ["ì¦‰ì‹œ_ìš°ì„ ", "ë§¥ë½_ìš°ì„ ", "ì „ëµ_ìš°ì„ ", "ê¶ê·¹_ìš°ì„ "], "default": "ë§¥ë½_ìš°ì„ "},
                        "required_models": {"type": "array", "items": {"type": "string"}, "default": ["ë¶„ì„ì _ì¶”ë¡ ", "ë¹„íŒì _ì¶”ë¡ "]},
                        "quality_threshold": {"type": "number", "default": 0.7}
                    },
                    "required": ["task_content"]
                }
            },
            
            # 5. ì‘ì—… í”„ë¡œì„¸ìŠ¤ ê°•ì œí™” ë„êµ¬
            {
                "name": "process_user_instruction",
                "description": "ì‚¬ìš©ì ì§€ì‹œ ì²˜ë¦¬ (í”¼ë“œë°± ì‹œìŠ¤í…œ ì ìš©)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "user_request": {"type": "string"},
                        "context": {"type": "object", "optional": True}
                    },
                    "required": ["user_request"]
                }
            },
            
            {
                "name": "process_feedback_response",
                "description": "ì‚¬ìš©ì í”¼ë“œë°± ì‘ë‹µ ì²˜ë¦¬",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "feedback_id": {"type": "string"},
                        "user_response": {"type": "string"}
                    },
                    "required": ["feedback_id", "user_response"]
                }
            },
            
            # 6. ë§¥ë½ ë¬¸ì„œ ê´€ë¦¬ ë„êµ¬
            {
                "name": "add_user_instruction",
                "description": "ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ ì¶”ê°€ (ì‚­ì œê¸ˆì§€)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "user_request": {"type": "string"},
                        "agent_response": {"type": "string", "optional": True},
                        "actual_implementation": {"type": "string", "optional": True},
                        "status": {"type": "string", "default": "in_progress"}
                    },
                    "required": ["user_request"]
                }
            },
            
            {
                "name": "add_feature_spec",
                "description": "ê¸°ëŠ¥ëª…ì„¸ì„œ ì¶”ê°€ (Git-style ê´€ë¦¬)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "feature_name": {"type": "string"},
                        "description": {"type": "string"},
                        "status": {"type": "string", "default": "planned"},
                        "dependencies": {"type": "array", "items": {"type": "string"}, "optional": True},
                        "implementation_notes": {"type": "string", "optional": True}
                    },
                    "required": ["feature_name", "description"]
                }
            },
            
            {
                "name": "search_context",
                "description": "ë§¥ë½ ê²€ìƒ‰ (ë¬¸ì„œ ì „ì²´)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "document_types": {"type": "array", "items": {"type": "string"}, "optional": True}
                    },
                    "required": ["query"]
                }
            },
            
            {
                "name": "get_project_summary",
                "description": "í”„ë¡œì íŠ¸ ì „ì²´ ìš”ì•½",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            
            # 7. í†µí•© ì‹œìŠ¤í…œ ë„êµ¬
            {
                "name": "system_health_check",
                "description": "ì „ì²´ ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì ê²€",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "detailed": {"type": "boolean", "default": False}
                    }
                }
            },
            
            {
                "name": "performance_metrics",
                "description": "ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            
            # 8. í¬íŠ¸ ê´€ë¦¬ ë„êµ¬
            {
                "name": "get_project_port",
                "description": "í”„ë¡œì íŠ¸ìš© í¬íŠ¸ í• ë‹¹",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "project_name": {"type": "string"},
                        "service_name": {"type": "string", "default": "default"}
                    },
                    "required": ["project_name"]
                }
            },
            
            {
                "name": "register_new_project",
                "description": "ìƒˆ í”„ë¡œì íŠ¸ í¬íŠ¸ ë¸”ë¡ ë“±ë¡",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "project_name": {"type": "string"},
                        "description": {"type": "string", "optional": True}
                    },
                    "required": ["project_name"]
                }
            },
            
            {
                "name": "port_status_summary",
                "description": "ì „ì²´ í¬íŠ¸ ìƒíƒœ ìš”ì•½",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            
            {
                "name": "run_port_forgetting_cycle",
                "description": "í¬íŠ¸ ë§ê° ì‚¬ì´í´ ì‹¤í–‰ (ì‹œê°„+ì‚¬ìš©ë¹ˆë„ ê¸°ë°˜)",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            
            # 9. ì˜ˆì¸¡ì  í”¼ë“œë°± ë° ê·œì¹™ ê²©ë¦¬ ë„êµ¬
            {
                "name": "analyze_user_intention",
                "description": "ì‚¬ìš©ì ì˜ë„ ì˜ˆì¸¡ì  ë¶„ì„ (ê³¼ê±° ê·¼ê±° + ë¯¸ë˜ ì˜ˆì¸¡)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "user_request": {"type": "string"},
                        "conversation_history": {"type": "array", "items": {"type": "string"}, "optional": True}
                    },
                    "required": ["user_request"]
                }
            },
            
            {
                "name": "check_rule_contamination",
                "description": "í”„ë¡œì íŠ¸ ê·œì¹™ ì˜¤ì—¼ ê²€ì‚¬ (ì „ì—­/í”„ë¡œì íŠ¸ ë¶„ë¦¬ í™•ì¸)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "project_name": {"type": "string"}
                    },
                    "required": ["project_name"]
                }
            },
            
            {
                "name": "add_rule_with_isolation",
                "description": "ê·œì¹™ ì¶”ê°€ (ì˜¤ì—¼ ë°©ì§€ ê²€ì‚¬ í¬í•¨)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "content": {"type": "string"},
                        "rule_type": {"type": "string", "enum": ["íŒ¨í„´", "ê°€ì´ë“œë¼ì¸", "ì„ í˜¸ë„", "ì œì•½ì¡°ê±´", "ì›Œí¬í”Œë¡œìš°"]},
                        "scope": {"type": "string", "enum": ["ì „ì—­", "í”„ë¡œì íŠ¸", "ì„¸ì…˜", "ì„ì‹œ"]},
                        "project_name": {"type": "string", "optional": True},
                        "source_context": {"type": "string", "optional": True}
                    },
                    "required": ["content", "rule_type", "scope"]
                }
            },
            
            # 10. í„°ë¯¸ë„ ì„¸ì…˜ ì¶”ì  ë„êµ¬
            {
                "name": "get_terminal_session_info",
                "description": "í˜„ì¬ í„°ë¯¸ë„ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            
            {
                "name": "search_conversation_history",
                "description": "ëŒ€í™” ë‚´ì—­ ê²€ìƒ‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "time_range_hours": {"type": "number", "default": 24},
                        "limit": {"type": "number", "default": 10}
                    },
                    "required": ["query"]
                }
            },
            
            {
                "name": "get_task_history",
                "description": "ì‘ì—… ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "task_type": {"type": "string", "optional": True},
                        "status": {"type": "string", "enum": ["COMPLETED", "ERROR", "BLOCKED"], "optional": True},
                        "limit": {"type": "number", "default": 20}
                    }
                }
            },
            
            {
                "name": "restore_previous_context",
                "description": "ì´ì „ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë³µì›",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "hours_back": {"type": "number", "default": 24}
                    }
                }
            },
            
            {
                "name": "get_session_statistics",
                "description": "í„°ë¯¸ë„ ì„¸ì…˜ í†µê³„ ì •ë³´",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "include_performance": {"type": "boolean", "default": True}
                    }
                }
            }
        ]
        
        return {"tools": tools}

    async def _save_conversation_record(self, conversation_id: str, task_id: str, 
                                       tracking_info: Dict, request: Dict, response: Dict):
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        try:
            with self.session_db_lock:
                with sqlite3.connect(str(self.session_db_path)) as conn:
                    conn.execute('''
                        INSERT OR REPLACE INTO conversations 
                        (conversation_id, terminal_id, timestamp, request_data, response_data, task_id, status)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        conversation_id,
                        self.terminal_id,
                        tracking_info["timestamp"],
                        json.dumps(request),
                        json.dumps(response),
                        task_id,
                        "COMPLETED" if "error" not in response else "ERROR"
                    ))
                    
                    # ì‘ì—… ì¶”ì  ì •ë³´ë„ ì €ì¥
                    if task_id:
                        conn.execute('''
                            INSERT OR REPLACE INTO task_tracking
                            (task_id, terminal_id, created_at, updated_at, task_type, status, progress_data)
                            VALUES (?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            task_id,
                            self.terminal_id,
                            tracking_info["timestamp"],
                            datetime.now(timezone.utc).isoformat(),
                            request.get("params", {}).get("name", "unknown"),
                            "COMPLETED" if "error" not in response else "ERROR",
                            json.dumps({"response_time": time.time() - tracking_info["request_start"]})
                        ))
                        
        except Exception as e:
            self.logger.error(f"ëŒ€í™” ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")

    async def _save_context_snapshot(self):
        """ë§¥ë½ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        try:
            # í˜„ì¬ ë§¥ë½ ì •ë³´ ìˆ˜ì§‘
            context_data = {
                "conversation_count": self.conversation_counter,
                "task_count": self.task_counter,
                "performance_metrics": self.performance_metrics.copy(),
                "context_memory": self.context_memory.copy()
            }
            
            with self.session_db_lock:
                with sqlite3.connect(str(self.session_db_path)) as conn:
                    conn.execute('''
                        INSERT INTO context_snapshots 
                        (terminal_id, snapshot_time, context_data, metadata)
                        VALUES (?, ?, ?, ?)
                    ''', (
                        self.terminal_id,
                        datetime.now(timezone.utc).isoformat(),
                        pickle.dumps(context_data),
                        json.dumps({"snapshot_type": "periodic", "version": self.version})
                    ))
                    
        except Exception as e:
            self.logger.error(f"ë§¥ë½ ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨: {e}")

    async def _check_infinite_loop_risk(self, method: str, params: Dict[str, Any]) -> bool:
        """ë¬´í•œë£¨í”„ ìœ„í—˜ ì²´í¬"""
        try:
            # ìµœê·¼ 10ì´ˆ ë‚´ ë™ì¼í•œ ìš”ì²­ íšŸìˆ˜ ì²´í¬
            recent_time = (datetime.now(timezone.utc) - timedelta(seconds=10)).isoformat()
            
            with sqlite3.connect(str(self.session_db_path)) as conn:
                cursor = conn.execute('''
                    SELECT COUNT(*) FROM conversations 
                    WHERE terminal_id = ? AND timestamp > ? 
                    AND json_extract(request_data, '$.method') = ?
                ''', (self.terminal_id, recent_time, method))
                
                count = cursor.fetchone()[0]
                
                # 10ì´ˆ ë‚´ ê°™ì€ ë©”ì„œë“œ 20íšŒ ì´ìƒ í˜¸ì¶œ ì‹œ ë¬´í•œë£¨í”„ë¡œ íŒë‹¨
                if count >= 20:
                    return True
                    
                # íŠ¹ì • ë„êµ¬ì˜ ì—°ì† í˜¸ì¶œ ì²´í¬
                if method == "tools/call":
                    tool_name = params.get("name", "")
                    cursor = conn.execute('''
                        SELECT COUNT(*) FROM conversations 
                        WHERE terminal_id = ? AND timestamp > ?
                        AND json_extract(request_data, '$.params.name') = ?
                    ''', (self.terminal_id, recent_time, tool_name))
                    
                    tool_count = cursor.fetchone()[0]
                    if tool_count >= 10:  # ê°™ì€ ë„êµ¬ 10íšŒ ì´ìƒ
                        return True
                        
        except Exception as e:
            self.logger.warning(f"ë¬´í•œë£¨í”„ ì²´í¬ ì‹¤íŒ¨: {e}")
            
        return False

    async def call_tool(self, params: Dict[str, Any], tracking_info: Dict[str, Any] = None) -> Dict[str, Any]:
        """ë„êµ¬ ì‹¤í–‰ (ì¶”ì  ì •ë³´ í¬í•¨)"""
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        # ì¶”ì  ì •ë³´ê°€ ìˆìœ¼ë©´ ë¡œê·¸ì— ê¸°ë¡
        if tracking_info:
            self.logger.info(f"[{tracking_info.get('conversation_id')}] ë„êµ¬ ì‹¤í–‰: {tool_name}")
        
        try:
            if tool_name == "sequential_thinking":
                return await self.sequential_thinking(arguments)
            elif tool_name == "create_project_context":
                return await self.create_project_context(arguments)
            elif tool_name == "update_global_context":
                return await self.update_global_context(arguments)
            elif tool_name == "query_context":
                return await self.query_context(arguments)
            elif tool_name == "execute_forgetting_cycle":
                return await self.execute_forgetting_cycle(arguments)
            elif tool_name == "create_sandbox":
                return await self.create_sandbox(arguments)
            elif tool_name == "execute_in_sandbox":
                return await self.execute_in_sandbox(arguments)
            elif tool_name == "get_sandbox_status":
                return await self.get_sandbox_status(arguments)
            elif tool_name == "destroy_sandbox":
                return await self.destroy_sandbox(arguments)
            elif tool_name == "thinking_advancement":
                return await self.thinking_advancement(arguments)
            elif tool_name == "process_user_instruction":
                return await self.process_user_instruction(arguments)
            elif tool_name == "process_feedback_response":
                return await self.process_feedback_response(arguments)
            elif tool_name == "add_user_instruction":
                return await self.add_user_instruction(arguments)
            elif tool_name == "add_feature_spec":
                return await self.add_feature_spec(arguments)
            elif tool_name == "search_context":
                return await self.search_context(arguments)
            elif tool_name == "get_project_summary":
                return await self.get_project_summary(arguments)
            elif tool_name == "system_health_check":
                return await self.system_health_check(arguments)
            elif tool_name == "performance_metrics":
                return await self.performance_metrics_tool(arguments)
            elif tool_name == "get_project_port":
                return await self.get_project_port_tool(arguments)
            elif tool_name == "register_new_project":
                return await self.register_new_project_tool(arguments)
            elif tool_name == "port_status_summary":
                return await self.port_status_summary_tool(arguments)
            elif tool_name == "run_port_forgetting_cycle":
                return await self.run_port_forgetting_cycle_tool(arguments)
            elif tool_name == "analyze_user_intention":
                return await self.analyze_user_intention_tool(arguments)
            elif tool_name == "check_rule_contamination":
                return await self.check_rule_contamination_tool(arguments)
            elif tool_name == "add_rule_with_isolation":
                return await self.add_rule_with_isolation_tool(arguments)
            elif tool_name == "get_terminal_session_info":
                return await self.get_terminal_session_info_tool(arguments)
            elif tool_name == "search_conversation_history":
                return await self.search_conversation_history_tool(arguments)
            elif tool_name == "get_task_history":
                return await self.get_task_history_tool(arguments)
            elif tool_name == "restore_previous_context":
                return await self.restore_previous_context_tool(arguments)
            elif tool_name == "get_session_statistics":
                return await self.get_session_statistics_tool(arguments)
            else:
                return {"error": f"Unknown tool: {tool_name}"}
                
        except Exception as e:
            self.logger.error(f"Tool execution error: {e}")
            return {"error": str(e)}

    # === ë©”íƒ€ì¸ì§€ ë„êµ¬ êµ¬í˜„ ===
    async def sequential_thinking(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """Sequential Thinking ì‹¤í–‰"""
        request = args["request"]
        context = args.get("context", {})
        
        thinking_sequence = self.meta_cognitive.execute_sequential_thinking(request, context)
        summary = self.meta_cognitive.get_thinking_summary(thinking_sequence)
        
        result_text = f"ğŸ§  Sequential Thinking ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ“Š ì‚¬ê³  ë‹¨ê³„: {summary['total_stages']}ê°œ\\n"
        result_text += f"ğŸ¯ í‰ê·  ë¶ˆí™•ì‹¤ì„±: {summary['average_uncertainty']:.2f}\\n"
        result_text += f"âš ï¸ í¸í–¥ íƒì§€: {summary['total_biases_detected']}ê°œ\\n"
        result_text += f"âœ¨ ì‚¬ê³  í’ˆì§ˆ: {summary['overall_thinking_quality']:.2f}/1.0\\n\\n"
        
        result_text += "ğŸ“‹ ì‚¬ê³  ê³¼ì •:\\n"
        for i, thinking in enumerate(thinking_sequence, 1):
            result_text += f"{i}. {thinking.stage.value}: ë¶ˆí™•ì‹¤ì„± {thinking.uncertainty:.2f}\\n"
        
        if summary['final_recommendation']:
            result_text += f"\\nğŸ’¡ ìµœì¢… ê¶Œê³ ì‚¬í•­:\\n{summary['final_recommendation'][:200]}..."
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ë§¥ë½ ê´€ë¦¬ ë„êµ¬ êµ¬í˜„ ===
    async def create_project_context(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ë§¥ë½ ìƒì„±"""
        project_name = args["project_name"]
        project_path = args["project_path"]
        content = args["content"]
        
        context_id = self.context_manager.update_project_context(project_name, content)
        
        result_text = f"ğŸ“‚ í”„ë¡œì íŠ¸ ë§¥ë½ ìƒì„± ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ·ï¸ í”„ë¡œì íŠ¸: {project_name}\\n"
        result_text += f"ğŸ“ ê²½ë¡œ: {project_path}\\n"
        result_text += f"ğŸ†” ë§¥ë½ ID: {context_id}\\n"
        result_text += f"ğŸ“Š ë§¥ë½ ë ˆë²¨: í”„ë¡œì íŠ¸\\n"
        result_text += f"ğŸ’¾ ë©”ëª¨ë¦¬ íƒ€ì…: ì‘ì—…ë©”ëª¨ë¦¬\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def update_global_context(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì—­ ë§¥ë½ ì—…ë°ì´íŠ¸"""
        content = args["content"]
        
        context_id = self.context_manager.update_global_context(content)
        
        result_text = f"ğŸŒ ì „ì—­ ë§¥ë½ ì—…ë°ì´íŠ¸ ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ†” ë§¥ë½ ID: {context_id}\\n"
        result_text += f"ğŸ“Š ë§¥ë½ ë ˆë²¨: ì „ì—­\\n"
        result_text += f"ğŸ’¾ ë©”ëª¨ë¦¬ íƒ€ì…: ì¥ê¸°ë©”ëª¨ë¦¬\\n"
        result_text += f"â° ìƒì„± ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def query_context(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ë§¥ë½ ê²€ìƒ‰"""
        query_text = args["query_text"]
        context_level_str = args.get("context_level")
        relevance_threshold = args.get("relevance_threshold", 0.5)
        
        # ë¬¸ìì—´ì„ ContextLevel enumìœ¼ë¡œ ë³€í™˜
        context_level = None
        if context_level_str:
            level_mapping = {
                "ì „ì—­": ContextLevel.GLOBAL,
                "í”„ë¡œì íŠ¸": ContextLevel.PROJECT,
                "ì„¸ì…˜": ContextLevel.SESSION,
                "ì¦‰ì‹œ": ContextLevel.IMMEDIATE
            }
            context_level = level_mapping.get(context_level_str)
        
        query = ContextQuery(
            query_text=query_text,
            context_level=context_level,
            relevance_threshold=relevance_threshold
        )
        
        results = self.context_manager.query_context(query)
        
        result_text = f"ğŸ” ë§¥ë½ ê²€ìƒ‰ ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ” ê²€ìƒ‰ì–´: {query_text}\\n"
        result_text += f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ\\n"
        result_text += f"ğŸ¯ ê´€ë ¨ì„± ì„ê³„ê°’: {relevance_threshold}\\n\\n"
        
        if results:
            result_text += "ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼:\\n"
            for i, result in enumerate(results[:5], 1):
                result_text += f"{i}. [{result.level.value}] ê´€ë ¨ì„±: {result.relevance_score:.2f}\\n"
                result_text += f"   ë‚´ìš©: {str(result.content)[:100]}...\\n\\n"
        else:
            result_text += "âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def execute_forgetting_cycle(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """8ì°¨ì› ë§ê° ì‚¬ì´í´ ì‹¤í–‰"""
        stats = self.context_manager.execute_forgetting_cycle()
        
        result_text = f"ğŸ§  8ì°¨ì› ë§ê° ì‚¬ì´í´ ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ“Š í‰ê°€ëœ ë…¸ë“œ: {stats['evaluated_nodes']}ê°œ\\n"
        result_text += f"ğŸ—‘ï¸ ë§ê°ëœ ë…¸ë“œ: {stats['forgotten_nodes']}ê°œ\\n"
        result_text += f"ğŸ’¾ ë³´ì¡´ëœ ë…¸ë“œ: {stats['preserved_nodes']}ê°œ\\n"
        result_text += f"ğŸ”„ ì—…ë°ì´íŠ¸ëœ ë…¸ë“œ: {stats['updated_scores']}ê°œ\\n\\n"
        
        forgetting_rate = stats['forgotten_nodes'] / stats['evaluated_nodes'] * 100 if stats['evaluated_nodes'] > 0 else 0
        result_text += f"ğŸ“ˆ ë§ê°ë¥ : {forgetting_rate:.1f}%\\n"
        
        if forgetting_rate > 50:
            result_text += "âš ï¸ ë†’ì€ ë§ê°ë¥  ê°ì§€ - ì¤‘ìš” ì •ë³´ ë³´ì¡´ ê²€í†  í•„ìš”\\n"
        elif forgetting_rate < 10:
            result_text += "âœ… ë‚®ì€ ë§ê°ë¥  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì–‘í˜¸\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ìƒŒë“œë°•ìŠ¤ ë„êµ¬ êµ¬í˜„ ===
    async def create_sandbox(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒŒë“œë°•ìŠ¤ ìƒì„±"""
        sandbox_id = args["sandbox_id"]
        project_path = args["project_path"]
        permission_level_str = args.get("permission_level", "ìƒŒë“œë°•ìŠ¤_ë ˆë²¨")
        network_allowed = args.get("network_allowed", False)
        time_limit = args.get("time_limit", 300)
        
        # ë¬¸ìì—´ì„ PermissionLevel enumìœ¼ë¡œ ë³€í™˜
        permission_mapping = {
            "ìƒŒë“œë°•ìŠ¤_ë ˆë²¨": PermissionLevel.SANDBOX,
            "ì‚¬ìš©ì_ë ˆë²¨": PermissionLevel.USER,
            "ê´€ë¦¬ì_ë ˆë²¨": PermissionLevel.ADMIN,
            "ì‹œìŠ¤í…œ_ë ˆë²¨": PermissionLevel.SYSTEM,
            "ê¶Œí•œ_ì—†ìŒ": PermissionLevel.NONE
        }
        permission_level = permission_mapping.get(permission_level_str, PermissionLevel.SANDBOX)
        
        config = SandboxConfig(
            sandbox_id=sandbox_id,
            project_path=project_path,
            allowed_paths=[project_path],
            forbidden_paths=["/System", "/usr", "/etc"],
            permission_level=permission_level,
            resource_limits={
                "cpu_percent": 30,
                "memory_mb": 512,
                "process_count": 5
            },
            network_allowed=network_allowed,
            time_limit=time_limit,
            auto_cleanup=True
        )
        
        result = self.sandbox_manager.create_sandbox(config)
        
        if result["status"] == "SUCCESS":
            result_text = f"ğŸ”’ ìƒŒë“œë°•ìŠ¤ ìƒì„± ì™„ë£Œ\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤ ID: {sandbox_id}\\n"
            result_text += f"ğŸ“‚ í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_path}\\n"
            result_text += f"ğŸ” ê¶Œí•œ ë ˆë²¨: {permission_level_str}\\n"
            result_text += f"ğŸŒ ë„¤íŠ¸ì›Œí¬ í—ˆìš©: {'ì˜ˆ' if network_allowed else 'ì•„ë‹ˆì˜¤'}\\n"
            result_text += f"â±ï¸ ì‹œê°„ ì œí•œ: {time_limit}ì´ˆ\\n"
            result_text += f"ğŸ“Š ìœ„í—˜ë„: {result['risk_assessment']['risk_level']}\\n"
            
            # ë¦¬ì†ŒìŠ¤ ì œí•œ í‘œì‹œ
            result_text += f"\\nğŸ’» ë¦¬ì†ŒìŠ¤ ì œí•œ:\\n"
            result_text += f"  â€¢ CPU: 30%\\n"
            result_text += f"  â€¢ ë©”ëª¨ë¦¬: 512MB\\n"
            result_text += f"  â€¢ í”„ë¡œì„¸ìŠ¤: 5ê°œ\\n"
        else:
            result_text = f"âŒ ìƒŒë“œë°•ìŠ¤ ìƒì„± ì‹¤íŒ¨\\n\\n"
            result_text += f"ğŸš« ì‚¬ìœ : {result.get('reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\\n"
            if 'risk_assessment' in result:
                result_text += f"ğŸ“Š ìœ„í—˜ë„: {result['risk_assessment']['total_risk']}/50\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def execute_in_sandbox(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒŒë“œë°•ìŠ¤ ë‚´ ëª…ë ¹ ì‹¤í–‰"""
        sandbox_id = args["sandbox_id"]
        command = args["command"]
        input_data = args.get("input_data")
        
        result = self.sandbox_manager.execute_in_sandbox(sandbox_id, command, input_data)
        
        if result["status"] == "SUCCESS":
            result_text = f"âœ… ëª…ë ¹ ì‹¤í–‰ ì™„ë£Œ\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤: {sandbox_id}\\n"
            result_text += f"ğŸ’» ëª…ë ¹ì–´: {command}\\n"
            result_text += f"ğŸ”¢ ë°˜í™˜ ì½”ë“œ: {result.get('return_code', 'N/A')}\\n"
            result_text += f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {result.get('execution_time', 0):.2f}ì´ˆ\\n\\n"
            
            if result.get("stdout"):
                result_text += f"ğŸ“¤ ì¶œë ¥:\\n{result['stdout'][:500]}\\n\\n"
            
            if result.get("stderr"):
                result_text += f"âš ï¸ ì˜¤ë¥˜:\\n{result['stderr'][:300]}\\n\\n"
            
            # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
            if result.get("resource_usage"):
                usage = result["resource_usage"]
                result_text += f"ğŸ“Š ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:\\n"
                result_text += f"  â€¢ CPU: {usage.get('cpu_percent', 0):.1f}%\\n"
                result_text += f"  â€¢ ë©”ëª¨ë¦¬: {usage.get('memory_mb', 0):.1f}MB\\n"
                
        elif result["status"] == "BLOCKED":
            result_text = f"ğŸš« ëª…ë ¹ ì‹¤í–‰ ì°¨ë‹¨\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤: {sandbox_id}\\n"
            result_text += f"ğŸ’» ëª…ë ¹ì–´: {command}\\n"
            result_text += f"ğŸš¨ ì°¨ë‹¨ ì‚¬ìœ : {result.get('reason', 'ì•Œ ìˆ˜ ì—†ìŒ')}\\n"
            
        elif result["status"] == "TIMEOUT":
            result_text = f"â° ëª…ë ¹ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤: {sandbox_id}\\n"
            result_text += f"ğŸ’» ëª…ë ¹ì–´: {command}\\n"
            result_text += f"ğŸ“ ë©”ì‹œì§€: {result.get('message', '')}\\n"
            
        else:
            result_text = f"âŒ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤: {sandbox_id}\\n"
            result_text += f"ğŸ’» ëª…ë ¹ì–´: {command}\\n"
            result_text += f"ğŸ“ ì˜¤ë¥˜: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def get_sandbox_status(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒŒë“œë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
        sandbox_id = args["sandbox_id"]
        
        status = self.sandbox_manager.get_sandbox_status(sandbox_id)
        
        if status["status"] == "ACTIVE":
            result_text = f"ğŸŸ¢ ìƒŒë“œë°•ìŠ¤ í™œì„± ìƒíƒœ\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤ ID: {sandbox_id}\\n"
            result_text += f"ğŸ” ê¶Œí•œ ë ˆë²¨: {status['permission_level']}\\n"
            result_text += f"ğŸŒ ë„¤íŠ¸ì›Œí¬ í—ˆìš©: {'ì˜ˆ' if status['network_allowed'] else 'ì•„ë‹ˆì˜¤'}\\n"
            result_text += f"ğŸ—‘ï¸ ìë™ ì •ë¦¬: {'ì˜ˆ' if status['auto_cleanup'] else 'ì•„ë‹ˆì˜¤'}\\n\\n"
            
            # í”„ë¡œì„¸ìŠ¤ ì •ë³´
            result_text += f"âš™ï¸ í”„ë¡œì„¸ìŠ¤ ìƒíƒœ:\\n"
            result_text += f"  â€¢ í™œì„±: {status['active_processes']}ê°œ\\n"
            result_text += f"  â€¢ ì´ê³„: {status['total_processes']}ê°œ\\n\\n"
            
            # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
            usage = status.get("resource_usage", {})
            limits = status.get("resource_limits", {})
            
            result_text += f"ğŸ“Š ë¦¬ì†ŒìŠ¤ í˜„í™©:\\n"
            result_text += f"  â€¢ CPU: {usage.get('cpu_percent', 0):.1f}% / {limits.get('cpu_percent', 0)}%\\n"
            result_text += f"  â€¢ ë©”ëª¨ë¦¬: {usage.get('memory_mb', 0):.1f}MB / {limits.get('memory_mb', 0)}MB\\n"
            result_text += f"  â€¢ ë””ìŠ¤í¬: {usage.get('disk_usage_mb', 0):.1f}MB\\n"
            
        else:
            result_text = f"ğŸ”´ ìƒŒë“œë°•ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤ ID: {sandbox_id}\\n"
            result_text += f"ğŸ“ ìƒíƒœ: {status['status']}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def destroy_sandbox(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒŒë“œë°•ìŠ¤ ì‚­ì œ"""
        sandbox_id = args["sandbox_id"]
        
        result = self.sandbox_manager.destroy_sandbox(sandbox_id)
        
        if result["status"] == "SUCCESS":
            result_text = f"ğŸ—‘ï¸ ìƒŒë“œë°•ìŠ¤ ì‚­ì œ ì™„ë£Œ\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤ ID: {sandbox_id}\\n"
            result_text += f"âš™ï¸ ì¢…ë£Œëœ í”„ë¡œì„¸ìŠ¤: {result['terminated_processes']}ê°œ\\n"
            result_text += f"ğŸ§¹ ì •ë¦¬ ì™„ë£Œ: {'ì˜ˆ' if result['cleaned_up'] else 'ì•„ë‹ˆì˜¤'}\\n"
        else:
            result_text = f"âŒ ìƒŒë“œë°•ìŠ¤ ì‚­ì œ ì‹¤íŒ¨\\n\\n"
            result_text += f"ğŸ†” ìƒŒë“œë°•ìŠ¤ ID: {sandbox_id}\\n"
            result_text += f"ğŸ“ ì˜¤ë¥˜: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ì‚¬ê³  ê³ ë„í™” ë„êµ¬ êµ¬í˜„ ===
    async def thinking_advancement(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ê³ ê¸‰ ì‚¬ê³  ì‹œìŠ¤í…œ"""
        task_content = args["task_content"]
        thinking_mode_str = args.get("thinking_mode", "ì‹¬ì¸µ_ì‚¬ê³ ")
        priority_str = args.get("priority", "ë§¥ë½_ìš°ì„ ")
        required_models_str = args.get("required_models", ["ë¶„ì„ì _ì¶”ë¡ ", "ë¹„íŒì _ì¶”ë¡ "])
        quality_threshold = args.get("quality_threshold", 0.7)
        
        # Enum ë³€í™˜
        thinking_mode_mapping = {
            "ì‹¬ì¸µ_ì‚¬ê³ ": ThinkingMode.DEEP,
            "ê´‘ë²”ìœ„_ì‚¬ê³ ": ThinkingMode.BROAD,
            "ì§‘ì¤‘_ì‚¬ê³ ": ThinkingMode.FOCUSED,
            "íƒìƒ‰_ì‚¬ê³ ": ThinkingMode.EXPLORATORY,
            "ìˆ˜ë ´_ì‚¬ê³ ": ThinkingMode.CONVERGENT,
            "ë°œì‚°_ì‚¬ê³ ": ThinkingMode.DIVERGENT
        }
        thinking_mode = thinking_mode_mapping.get(thinking_mode_str, ThinkingMode.DEEP)
        
        priority_mapping = {
            "ì¦‰ì‹œ_ìš°ì„ ": ContextualPriority.IMMEDIATE,
            "ë§¥ë½_ìš°ì„ ": ContextualPriority.CONTEXTUAL,
            "ì „ëµ_ìš°ì„ ": ContextualPriority.STRATEGIC,
            "ê¶ê·¹_ìš°ì„ ": ContextualPriority.ULTIMATE
        }
        priority = priority_mapping.get(priority_str, ContextualPriority.CONTEXTUAL)
        
        model_mapping = {
            "ë¶„ì„ì _ì¶”ë¡ ": ReasoningModel.ANALYTICAL,
            "ì°½ì˜ì _ì¶”ë¡ ": ReasoningModel.CREATIVE,
            "ë¹„íŒì _ì¶”ë¡ ": ReasoningModel.CRITICAL,
            "ì²´ê³„ì _ì¶”ë¡ ": ReasoningModel.SYSTEMATIC,
            "ì§ê´€ì _ì¶”ë¡ ": ReasoningModel.INTUITIVE,
            "í™•ë¥ ì _ì¶”ë¡ ": ReasoningModel.PROBABILISTIC
        }
        required_models = [model_mapping.get(m, ReasoningModel.ANALYTICAL) for m in required_models_str]
        
        task = ThinkingTask(
            task_id=f"task_{int(time.time())}",
            content=task_content,
            context={"source": "mcp_request"},
            required_models=required_models,
            thinking_mode=thinking_mode,
            priority=priority,
            quality_threshold=quality_threshold
        )
        
        result = await self.thinking_engine.advance_thinking(task)
        
        result_text = f"ğŸ¯ ì‚¬ê³  ê³ ë„í™” ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ“‹ ì‘ì—… ID: {result.task_id}\\n"
        result_text += f"ğŸ§  ì‚¬ê³  ëª¨ë“œ: {thinking_mode_str}\\n"
        result_text += f"â­ ìš°ì„ ìˆœìœ„: {priority_str}\\n"
        result_text += f"ğŸ“Š ê³ ë„í™” ì ìˆ˜: {result.advancement_score:.2f}/1.0\\n"
        result_text += f"âœ¨ ì „ì²´ í’ˆì§ˆ: {result.quality_metrics['overall_quality']:.2f}/1.0\\n\\n"
        
        # Sequential thinking ë‹¨ê³„
        result_text += f"ğŸ”„ Sequential Thinking ë‹¨ê³„:\\n"
        for step in result.sequential_steps:
            result_text += f"  â€¢ {step['stage']}: í’ˆì§ˆ {step['quality_score']:.2f}\\n"
        
        # ì„ íƒëœ ì ‘ê·¼ë²•
        chosen_approach = result.contextual_decision['chosen_approach']
        result_text += f"\\nğŸ¯ ì„ íƒëœ ì ‘ê·¼ë²•: {chosen_approach}\\n"
        
        # ìµœì¢… ê¶Œê³ ì•ˆ (ìš”ì•½)
        recommendation_lines = result.final_recommendation.split('\\n')[:5]
        result_text += f"\\nğŸ’¡ ìµœì¢… ê¶Œê³ ì‚¬í•­:\\n"
        for line in recommendation_lines:
            if line.strip():
                result_text += f"  {line.strip()[:80]}...\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ì‘ì—… í”„ë¡œì„¸ìŠ¤ ê°•ì œí™” ë„êµ¬ êµ¬í˜„ ===
    async def process_user_instruction(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§€ì‹œ ì²˜ë¦¬ (í”¼ë“œë°± ì‹œìŠ¤í…œ ì ìš©)"""
        user_request = args["user_request"]
        context = args.get("context", {})
        
        result = self.work_enforcer.process_user_instruction(user_request, context)
        
        if result["status"] == "BLOCKED":
            result_text = f"ğŸš« ì‘ì—… ì°¨ë‹¨\\n\\n"
            result_text += f"ğŸ“ ìš”ì²­: {user_request[:100]}...\\n"
            result_text += f"âŒ ì°¨ë‹¨ ì‚¬ìœ : {result['reason']}\\n\\n"
            result_text += "ìœ„ë°˜ ì‚¬í•­:\\n"
            for violation in result['violations']:
                result_text += f"  â€¢ {violation}\\n"
        
        elif result["status"] == "FEEDBACK_REQUIRED":
            feedback = result["feedback"]
            result_text = f"ğŸ’¬ ì‘ì—… í”¼ë“œë°± ìš”ì²­\\n\\n"
            result_text += f"ğŸ“ ìš”ì²­: {user_request[:100]}...\\n"
            result_text += f"ğŸ†” í”¼ë“œë°± ID: {feedback.feedback_id}\\n\\n"
            
            result_text += "ğŸ“‹ ì‘ì—… ë‹¨ê³„:\\n"
            for step in feedback.work_steps:
                result_text += f"  â€¢ {step}\\n"
            
            result_text += "\\nğŸ¯ ì˜ë„ íŒŒì•…:\\n"
            for intention in feedback.intentions:
                result_text += f"  â€¢ {intention}\\n"
            
            result_text += "\\nâš ï¸ ìœ„í—˜ ìš”ì†Œ:\\n"
            for risk in feedback.risks:
                result_text += f"  â€¢ {risk}\\n"
            
            result_text += "\\nğŸ’¡ ëŒ€ì•ˆ:\\n"
            for alt in feedback.alternatives:
                result_text += f"  â€¢ {alt}\\n"
            
            result_text += f"\\nâœ… ìœ„ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (í”¼ë“œë°± ID: {feedback.feedback_id})"
        
        else:  # PROCEED
            result_text = f"âœ… ì‘ì—… ì§„í–‰\\n\\n"
            result_text += f"ğŸ“ ìš”ì²­: {user_request}\\n"
            result_text += f"ğŸ”„ ì‘ì—… ìœ í˜•: {result['instruction'].work_type.value}\\n"
            result_text += f"ğŸ“Š ë³µì¡ë„: {result['instruction'].complexity_level}/10\\n"
            result_text += f"âš ï¸ ìœ„í—˜ë„: {result['instruction'].risk_level}/10\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def process_feedback_response(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì í”¼ë“œë°± ì‘ë‹µ ì²˜ë¦¬"""
        feedback_id = args["feedback_id"]
        user_response = args["user_response"]
        
        result = self.work_enforcer.process_user_feedback_response(feedback_id, user_response)
        
        if result["status"] == "APPROVED":
            result_text = f"âœ… ì‘ì—… ìŠ¹ì¸ë¨\\n\\n"
            result_text += f"ğŸ“ ìµœì¢… ê³„íš:\\n"
            for step in result['final_plan']:
                result_text += f"  â€¢ {step}\\n"
        
        elif result["status"] == "CLARIFICATION_NEEDED":
            feedback = result["feedback"]
            result_text = f"â“ ì¶”ê°€ ëª…í™•í™” í•„ìš”\\n\\n"
            result_text += f"ğŸ†” ìƒˆ í”¼ë“œë°± ID: {feedback.feedback_id}\\n\\n"
            result_text += "ëª…í™•í™” ì§ˆë¬¸:\\n"
            for question in feedback.alternatives:
                result_text += f"  â€¢ {question}\\n"
        
        elif result["status"] == "MAX_FEEDBACK_REACHED":
            result_text = f"â³ ìµœëŒ€ í”¼ë“œë°± íšŸìˆ˜ ë„ë‹¬\\n\\n"
            result_text += "í˜„ì¬ ì´í•´ ê¸°ì¤€ìœ¼ë¡œ ì‘ì—…ì„ ì§„í–‰í•©ë‹ˆë‹¤."
        
        elif result["status"] == "CANCELLED":
            result_text = f"âŒ ì‘ì—… ì·¨ì†Œë¨\\n\\n"
            result_text += f"ì·¨ì†Œ ì‚¬ìœ : {result['reason']}"
        
        else:
            result_text = f"âŒ ì˜¤ë¥˜ ë°œìƒ\\n\\n{result['message']}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ë§¥ë½ ë¬¸ì„œ ê´€ë¦¬ ë„êµ¬ êµ¬í˜„ ===
    async def add_user_instruction(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ ì¶”ê°€"""
        user_request = args["user_request"]
        agent_response = args.get("agent_response", "")
        actual_implementation = args.get("actual_implementation", "")
        status = args.get("status", "in_progress")
        
        instruction_id = self.context_document_manager.add_user_instruction(
            user_request, agent_response, actual_implementation, status
        )
        
        result_text = f"ğŸ“ ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ ì¶”ê°€ ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ†” ì§€ì‹œì‚¬í•­ ID: {instruction_id}\\n"
        result_text += f"ğŸ“‹ ìš”ì²­: {user_request[:100]}...\\n"
        result_text += f"ğŸ“Š ìƒíƒœ: {status}\\n"
        result_text += f"ğŸ“ ì €ì¥ ìœ„ì¹˜: .claude/context/user_instructions.json\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def add_feature_spec(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ëŠ¥ëª…ì„¸ì„œ ì¶”ê°€"""
        feature_name = args["feature_name"]
        description = args["description"]
        status = args.get("status", "planned")
        dependencies = args.get("dependencies", [])
        implementation_notes = args.get("implementation_notes", "")
        
        feature_id = self.context_document_manager.add_feature_spec(
            feature_name, description, status, dependencies, implementation_notes
        )
        
        result_text = f"ğŸ“‹ ê¸°ëŠ¥ëª…ì„¸ì„œ ì¶”ê°€ ì™„ë£Œ\\n\\n"
        result_text += f"ğŸ†” ê¸°ëŠ¥ ID: {feature_id}\\n"
        result_text += f"ğŸ·ï¸ ê¸°ëŠ¥ëª…: {feature_name}\\n"
        result_text += f"ğŸ“Š ìƒíƒœ: {status}\\n"
        result_text += f"ğŸ“ ì„¤ëª…: {description[:100]}...\\n"
        result_text += f"ğŸ“ ì €ì¥ ìœ„ì¹˜: .claude/context/feature_specifications.json\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def search_context(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ë§¥ë½ ê²€ìƒ‰"""
        query = args["query"]
        document_types = args.get("document_types")
        
        results = self.context_document_manager.search_context(query, document_types)
        
        result_text = f"ğŸ” ë§¥ë½ ê²€ìƒ‰ ê²°ê³¼\\n\\n"
        result_text += f"ğŸ” ê²€ìƒ‰ì–´: {query}\\n\\n"
        
        for doc_type, items in results.items():
            if items:
                result_text += f"ğŸ“‚ {doc_type.upper()} ({len(items)}ê°œ ë°œê²¬):\\n"
                for item in items[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    if hasattr(item, 'user_request'):
                        result_text += f"  â€¢ {item.user_request[:80]}...\\n"
                    elif hasattr(item, 'feature_name'):
                        result_text += f"  â€¢ {item.feature_name}: {item.description[:60]}...\\n"
                    elif hasattr(item, 'component_name'):
                        result_text += f"  â€¢ {item.component_name}: {item.description[:60]}...\\n"
                result_text += "\\n"
        
        if not any(results.values()):
            result_text += "âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def get_project_summary(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ì „ì²´ ìš”ì•½"""
        summary = self.context_document_manager.get_project_summary()
        
        result_text = f"ğŸ“Š í”„ë¡œì íŠ¸ ìš”ì•½\\n\\n"
        result_text += f"ğŸ·ï¸ í”„ë¡œì íŠ¸: {summary['project_metadata']['project_name']}\\n"
        result_text += f"ğŸ“… ìƒì„±ì¼: {summary['project_metadata']['created_at'][:10]}\\n"
        result_text += f"ğŸ”„ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {summary['project_metadata']['last_updated'][:10]}\\n\\n"
        
        stats = summary['statistics']
        result_text += f"ğŸ“ˆ í†µê³„:\\n"
        result_text += f"  â€¢ ì´ ì§€ì‹œì‚¬í•­: {stats['total_instructions']}ê°œ\\n"
        result_text += f"  â€¢ ì™„ë£Œëœ ì§€ì‹œì‚¬í•­: {stats['completed_instructions']}ê°œ\\n"
        result_text += f"  â€¢ ì™„ë£Œìœ¨: {stats['completion_rate']:.1f}%\\n"
        result_text += f"  â€¢ í™œì„± ê¸°ëŠ¥: {stats['active_features']}ê°œ\\n"
        result_text += f"  â€¢ ì´ ëŒ€í™”: {stats['total_conversations']}íšŒ\\n\\n"
        
        if summary['top_tags']:
            result_text += f"ğŸ·ï¸ ì£¼ìš” íƒœê·¸:\\n"
            for tag, count in summary['top_tags'][:5]:
                result_text += f"  â€¢ {tag}: {count}íšŒ\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === í¬íŠ¸ ê´€ë¦¬ ë„êµ¬ êµ¬í˜„ ===
    async def get_project_port_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ìš© í¬íŠ¸ í• ë‹¹"""
        project_name = args["project_name"]
        service_name = args.get("service_name", "default")
        
        try:
            port = get_project_port(project_name, service_name)
            port_info = self.port_manager.get_project_port_info(project_name)
            
            result_text = f"ğŸš¢ í¬íŠ¸ í• ë‹¹ ì™„ë£Œ\\n\\n"
            result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {project_name}\\n"
            result_text += f"ğŸ”Œ í• ë‹¹ëœ í¬íŠ¸: {port}\\n"
            result_text += f"âš™ï¸ ì„œë¹„ìŠ¤: {service_name}\\n"
            if port_info:
                result_text += f"ğŸ“Š í¬íŠ¸ ë²”ìœ„: {port_info['port_range']}\\n"
                result_text += f"ğŸ”„ ìƒíƒœ: {port_info['status']}\\n"
                result_text += f"ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸: {port_info['available_ports']}ê°œ\\n"
            
        except Exception as e:
            result_text = f"âŒ í¬íŠ¸ í• ë‹¹ ì‹¤íŒ¨\\n\\n"
            result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {project_name}\\n"
            result_text += f"ğŸ”¥ ì˜¤ë¥˜: {str(e)}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def register_new_project_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒˆ í”„ë¡œì íŠ¸ í¬íŠ¸ ë¸”ë¡ ë“±ë¡"""
        project_name = args["project_name"]
        description = args.get("description", "")
        
        result = register_project(project_name, description)
        
        if result["status"] == "success":
            result_text = f"âœ… í”„ë¡œì íŠ¸ ë“±ë¡ ì™„ë£Œ\\n\\n"
            result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {result['project_name']}\\n"
            result_text += f"ğŸš¢ í¬íŠ¸ ë²”ìœ„: {result['port_range']}\\n"
            result_text += f"ğŸ“Š í• ë‹¹ëœ í¬íŠ¸: {result['allocated_ports']}ê°œ\\n"
            result_text += f"ğŸ“ ì„¤ëª…: {description}\\n"
        elif result["status"] == "exists":
            result_text = f"âš ï¸ ì´ë¯¸ ë“±ë¡ëœ í”„ë¡œì íŠ¸\\n\\n"
            result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {project_name}\\n"
            result_text += f"ğŸ’¬ ë©”ì‹œì§€: {result['message']}\\n"
        else:
            result_text = f"âŒ í”„ë¡œì íŠ¸ ë“±ë¡ ì‹¤íŒ¨\\n\\n"
            result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {project_name}\\n"
            result_text += f"ğŸ”¥ ì˜¤ë¥˜: {result['message']}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def port_status_summary_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²´ í¬íŠ¸ ìƒíƒœ ìš”ì•½"""
        summary = self.port_manager.get_port_status_summary()
        
        result_text = f"ğŸ“Š í¬íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ ìƒíƒœ\\n\\n"
        result_text += f"ğŸ—ï¸ ì´ í”„ë¡œì íŠ¸: {summary['total_projects']}ê°œ\\n"
        result_text += f"ğŸŸ¢ í™œì„± ë¸”ë¡: {summary['active_blocks']}ê°œ\\n"
        result_text += f"ğŸŸ¡ ë¹„í™œì„± ë¸”ë¡: {summary['inactive_blocks']}ê°œ\\n"
        result_text += f"ğŸ”´ ë§ê°ëœ ë¸”ë¡: {summary['forgotten_blocks']}ê°œ\\n\\n"
        
        result_text += f"ğŸš¢ í• ë‹¹ëœ ì´ í¬íŠ¸: {summary['total_ports_allocated']}ê°œ\\n"
        result_text += f"â­ï¸ ë‹¤ìŒ ì‚¬ìš© ê°€ëŠ¥ ë¸”ë¡: {summary['next_available_block']}\\n"
        result_text += f"ğŸ“ˆ ìµœê·¼ 7ì¼ ì‚¬ìš©: {summary['recent_usage_count']}íšŒ\\n\\n"
        
        result_text += f"ğŸ”’ ì˜ˆì•½ëœ í”„ë¡œì íŠ¸:\\n"
        for project in summary['reserved_projects']:
            info = self.port_manager.get_project_port_info(project)
            if info:
                result_text += f"  â€¢ {project}: {info['port_range']} ({info['status']})\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def run_port_forgetting_cycle_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í¬íŠ¸ ë§ê° ì‚¬ì´í´ ì‹¤í–‰"""
        try:
            # ë§ê° ì‚¬ì´í´ ì‹¤í–‰ ì „ ìƒíƒœ
            before_summary = self.port_manager.get_port_status_summary()
            
            # ë§ê° ì‚¬ì´í´ ì‹¤í–‰
            self.port_manager.execute_forgetting_cycle()
            
            # ì‹¤í–‰ í›„ ìƒíƒœ
            after_summary = self.port_manager.get_port_status_summary()
            
            result_text = f"ğŸ§  í¬íŠ¸ ë§ê° ì‚¬ì´í´ ì‹¤í–‰ ì™„ë£Œ\\n\\n"
            result_text += f"ğŸ“Š ì‹¤í–‰ ì „/í›„ ë¹„êµ:\\n"
            result_text += f"  â€¢ í™œì„± ë¸”ë¡: {before_summary['active_blocks']} â†’ {after_summary['active_blocks']}\\n"
            result_text += f"  â€¢ ë¹„í™œì„± ë¸”ë¡: {before_summary['inactive_blocks']} â†’ {after_summary['inactive_blocks']}\\n"
            result_text += f"  â€¢ ë§ê°ëœ ë¸”ë¡: {before_summary['forgotten_blocks']} â†’ {after_summary['forgotten_blocks']}\\n\\n"
            
            # ì •ë¦¬ ì‹¤í–‰
            self.port_manager.execute_forgetting_cleanup()
            final_summary = self.port_manager.get_port_status_summary()
            
            result_text += f"ğŸ§¹ ì •ë¦¬ í›„ ìµœì¢… ìƒíƒœ:\\n"
            result_text += f"  â€¢ ì´ í”„ë¡œì íŠ¸: {final_summary['total_projects']}ê°œ\\n"
            result_text += f"  â€¢ í• ë‹¹ëœ í¬íŠ¸: {final_summary['total_ports_allocated']}ê°œ\\n"
            
            result_text += f"\\nğŸ’¡ ë§ê° ê¸°ì¤€: ì‹œê°„(60%) + ì‚¬ìš©ë¹ˆë„(40%)\\n"
            result_text += f"â° 6ê°œì›” ì´ìƒ ë¯¸ì‚¬ìš©ì‹œ ìë™ ì •ë¦¬\\n"
            
        except Exception as e:
            result_text = f"âŒ ë§ê° ì‚¬ì´í´ ì‹¤í–‰ ì‹¤íŒ¨\\n\\n"
            result_text += f"ğŸ”¥ ì˜¤ë¥˜: {str(e)}\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ì‹œìŠ¤í…œ ë„êµ¬ êµ¬í˜„ ===
    async def system_health_check(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì ê²€"""
        detailed = args.get("detailed", False)
        
        # ê° ì„œë¸Œì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        try:
            context_summary = self.context_manager.get_context_summary()
        except Exception:
            context_summary = {"total_nodes": 0}
        
        try:
            sandbox_list = self.sandbox_manager.list_sandboxes()
        except Exception:
            sandbox_list = {"total_sandboxes": 0}
        
        # ë©”íƒ€ì¸ì§€ì™€ ì‚¬ê³  ê³ ë„í™”ëŠ” ë¹ˆ ìƒíƒœë¡œ ì‹œì‘
        meta_cognitive_summary = {"total_tasks": 0, "average_quality": 0}
        thinking_summary = {"total_tasks": 0, "average_advancement_score": 0}
        
        result_text = f"ğŸ¥ BOOSAAN ULTIMATE ì‹œìŠ¤í…œ ê±´ê°• ì ê²€\\n\\n"
        
        # ì „ì²´ ìƒíƒœ
        total_score = 0.0
        component_count = 0
        
        # ë©”íƒ€ì¸ì§€ ì—”ì§„
        result_text += f"ğŸ§  ë©”íƒ€ì¸ì§€ ì—”ì§„: "
        if meta_cognitive_summary.get('total_tasks', 0) > 0:
            avg_quality = meta_cognitive_summary.get('average_quality', 0)
            result_text += f"âœ… ì •ìƒ (í’ˆì§ˆ: {avg_quality:.2f})\\n"
            total_score += avg_quality
        else:
            result_text += f"âš ï¸ ë¯¸ì‚¬ìš©\\n"
            total_score += 0.5
        component_count += 1
        
        # ë§¥ë½ ê´€ë¦¬
        result_text += f"ğŸ—ƒï¸ ë§¥ë½ ê´€ë¦¬: "
        total_nodes = context_summary.get('total_nodes', 0)
        if total_nodes > 0:
            result_text += f"âœ… ì •ìƒ ({total_nodes}ê°œ ë…¸ë“œ)\\n"
            total_score += 0.8
        else:
            result_text += f"âš ï¸ ë¹ˆ ë§¥ë½\\n"
            total_score += 0.3
        component_count += 1
        
        # ìƒŒë“œë°•ìŠ¤ ê´€ë¦¬
        result_text += f"ğŸ”’ ìƒŒë“œë°•ìŠ¤ ê´€ë¦¬: "
        total_sandboxes = sandbox_list.get('total_sandboxes', 0)
        result_text += f"âœ… ì •ìƒ ({total_sandboxes}ê°œ í™œì„±)\\n"
        total_score += 0.8
        component_count += 1
        
        # ì‚¬ê³  ê³ ë„í™”
        result_text += f"ğŸ¯ ì‚¬ê³  ê³ ë„í™”: "
        if thinking_summary.get('total_tasks', 0) > 0:
            avg_advancement = thinking_summary.get('average_advancement_score', 0)
            result_text += f"âœ… ì •ìƒ (ê³ ë„í™”: {avg_advancement:.2f})\\n"
            total_score += avg_advancement
        else:
            result_text += f"âš ï¸ ë¯¸ì‚¬ìš©\\n"
            total_score += 0.5
        component_count += 1
        
        # ì „ì²´ ê±´ê°• ì ìˆ˜
        overall_health = total_score / component_count if component_count > 0 else 0.5
        result_text += f"\\nğŸ“Š ì „ì²´ ê±´ê°• ì ìˆ˜: {overall_health:.2f}/1.0\\n"
        
        if overall_health >= 0.8:
            result_text += f"ğŸŸ¢ ì‹œìŠ¤í…œ ìƒíƒœ: ìš°ìˆ˜\\n"
        elif overall_health >= 0.6:
            result_text += f"ğŸŸ¡ ì‹œìŠ¤í…œ ìƒíƒœ: ì–‘í˜¸\\n"
        elif overall_health >= 0.4:
            result_text += f"ğŸŸ  ì‹œìŠ¤í…œ ìƒíƒœ: ì£¼ì˜\\n"
        else:
            result_text += f"ğŸ”´ ì‹œìŠ¤í…œ ìƒíƒœ: ìœ„í—˜\\n"
        
        # ìƒì„¸ ì •ë³´
        if detailed:
            result_text += f"\\nğŸ“‹ ìƒì„¸ ì •ë³´:\\n"
            result_text += f"  â€¢ ë©”íƒ€ì¸ì§€ ì²˜ë¦¬ ì‘ì—…: {meta_cognitive_summary.get('total_tasks', 0)}ê°œ\\n"
            result_text += f"  â€¢ ë§¥ë½ ë…¸ë“œ ìˆ˜: {total_nodes}ê°œ\\n"
            result_text += f"  â€¢ í™œì„± ìƒŒë“œë°•ìŠ¤: {total_sandboxes}ê°œ\\n"
            result_text += f"  â€¢ ì‚¬ê³  ê³ ë„í™” ì‘ì—…: {thinking_summary.get('total_tasks', 0)}ê°œ\\n"
            result_text += f"  â€¢ ì„±ëŠ¥ ë©”íŠ¸ë¦­:\\n"
            result_text += f"    - ì´ ìš”ì²­: {self.performance_metrics['total_requests']}ê°œ\\n"
            result_text += f"    - ì„±ê³µ ì‘ì—…: {self.performance_metrics['successful_operations']}ê°œ\\n"
            result_text += f"    - ì°¨ë‹¨ ì‘ì—…: {self.performance_metrics['blocked_operations']}ê°œ\\n"
            result_text += f"    - í‰ê·  ì‘ë‹µ: {self.performance_metrics['average_response_time']:.3f}ì´ˆ\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def performance_metrics_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        metrics = self.performance_metrics.copy()
        
        # ì„±ê³µë¥  ê³„ì‚°
        success_rate = 0.0
        if metrics['total_requests'] > 0:
            success_rate = metrics['successful_operations'] / metrics['total_requests'] * 100
        
        # ì°¨ë‹¨ë¥  ê³„ì‚°
        block_rate = 0.0
        if metrics['total_requests'] > 0:
            block_rate = metrics['blocked_operations'] / metrics['total_requests'] * 100
        
        result_text = f"ğŸ“Š BOOSAAN ULTIMATE ì„±ëŠ¥ ë©”íŠ¸ë¦­\\n\\n"
        result_text += f"ğŸ“ˆ ìš”ì²­ í†µê³„:\\n"
        result_text += f"  â€¢ ì´ ìš”ì²­ ìˆ˜: {metrics['total_requests']}ê°œ\\n"
        result_text += f"  â€¢ ì„±ê³µ ì‘ì—…: {metrics['successful_operations']}ê°œ ({success_rate:.1f}%)\\n"
        result_text += f"  â€¢ ì°¨ë‹¨ ì‘ì—…: {metrics['blocked_operations']}ê°œ ({block_rate:.1f}%)\\n\\n"
        
        result_text += f"â±ï¸ ì„±ëŠ¥ ì§€í‘œ:\\n"
        result_text += f"  â€¢ í‰ê·  ì‘ë‹µ ì‹œê°„: {metrics['average_response_time']:.3f}ì´ˆ\\n"
        
        # ì„±ëŠ¥ í‰ê°€
        if metrics['average_response_time'] < 0.1:
            response_status = "ğŸŸ¢ ë§¤ìš° ë¹ ë¦„"
        elif metrics['average_response_time'] < 0.5:
            response_status = "ğŸŸ¡ ë³´í†µ"
        elif metrics['average_response_time'] < 1.0:
            response_status = "ğŸŸ  ëŠë¦¼"
        else:
            response_status = "ğŸ”´ ë§¤ìš° ëŠë¦¼"
        
        result_text += f"  â€¢ ì‘ë‹µ ì†ë„: {response_status}\\n"
        
        # ë³´ì•ˆ ì§€í‘œ
        result_text += f"\\nğŸ”’ ë³´ì•ˆ ì§€í‘œ:\\n"
        result_text += f"  â€¢ ë³´ì•ˆ ì°¨ë‹¨ë¥ : {block_rate:.1f}%\\n"
        if block_rate > 20:
            result_text += f"  â€¢ ìƒíƒœ: ğŸ”´ ë†’ì€ ìœ„í—˜ ìš”ì²­ ë¹ˆë„\\n"
        elif block_rate > 5:
            result_text += f"  â€¢ ìƒíƒœ: ğŸŸ¡ ë³´í†µ ìœ„í—˜ ìš”ì²­\\n"
        else:
            result_text += f"  â€¢ ìƒíƒœ: ğŸŸ¢ ì•ˆì „í•œ ì‚¬ìš© íŒ¨í„´\\n"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === ì˜ˆì¸¡ì  í”¼ë“œë°± ë° ê·œì¹™ ê²©ë¦¬ ë„êµ¬ êµ¬í˜„ ===
    async def analyze_user_intention_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ì˜ˆì¸¡ì  ë¶„ì„ (ì˜ˆì¸¡í•˜ê³  í”¼ë“œë°±, ì ˆëŒ€ ì˜ˆì¸¡í•˜ê³  ìˆ˜í–‰ ì•ˆí•¨)"""
        user_request = args["user_request"]
        conversation_history = args.get("conversation_history", [])
        
        try:
            analysis = self.rule_isolation.analyze_user_intention(user_request, conversation_history)
            
            result_text = f"ğŸ§  ì‚¬ìš©ì ì˜ë„ ì˜ˆì¸¡ ë¶„ì„\\n\\n"
            result_text += f"ğŸ“ ìš”ì²­: {user_request[:100]}...\\n"
            result_text += f"ğŸ¯ ì˜ˆì¸¡ëœ ì˜ë„: {analysis.intention_type.value}\\n"
            result_text += f"ğŸ“Š ì‹ ë¢°ë„: {analysis.confidence_score:.2f}/1.0\\n\\n"
            
            # ê³¼ê±° ê·¼ê±°
            if analysis.past_context_evidence:
                result_text += f"ğŸ“š ê³¼ê±° ë§¥ë½ ê·¼ê±°:\\n"
                for evidence in analysis.past_context_evidence[:3]:
                    result_text += f"  â€¢ {evidence}\\n"
                result_text += "\\n"
            
            # ë¯¸ë˜ ì˜ˆì¸¡
            if analysis.future_implications:
                result_text += f"ğŸ”® ë¯¸ë˜ ê²°ê³¼ ì˜ˆì¸¡:\\n"
                for implication in analysis.future_implications[:3]:
                    result_text += f"  â€¢ {implication}\\n"
                result_text += "\\n"
            
            # ìœ„í—˜ ìš”ì†Œ
            if analysis.risk_factors:
                result_text += f"âš ï¸ ìœ„í—˜ ìš”ì†Œ:\\n"
                for risk in analysis.risk_factors[:2]:
                    result_text += f"  â€¢ {risk}\\n"
                result_text += "\\n"
            
            # ì¶”ì²œ ì‘ë‹µ ë°©ì‹
            result_text += f"ğŸ’¡ ì¶”ì²œ ì‘ë‹µ ë°©ì‹: {analysis.recommended_response}\\n\\n"
            
            # ëª…í™•í™” ì§ˆë¬¸ë“¤ (í•µì‹¬!)
            result_text += f"â“ ì˜ˆì¸¡ ê¸°ë°˜ í™•ì¸ ì§ˆë¬¸ë“¤:\\n"
            for i, question in enumerate(analysis.clarification_questions, 1):
                result_text += f"{i}. {question}\\n"
            
            if analysis.intention_type in [IntentionType.FRUSTRATION, IntentionType.IMPOSSIBLE_TASK]:
                result_text += "\\nğŸš« **ì¦‰ì‹œ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ìœ„ ì§ˆë¬¸ë“¤ë¡œ ì˜ë„ë¥¼ ëª…í™•íˆ í•œ í›„ ì§„í–‰í•˜ì„¸ìš”**"
            
        except Exception as e:
            result_text = f"âŒ ì˜ë„ ë¶„ì„ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def check_rule_contamination_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ê·œì¹™ ì˜¤ì—¼ ê²€ì‚¬"""
        project_name = args["project_name"]
        
        try:
            contamination_result = self.rule_isolation.check_rule_contamination(project_name)
            
            result_text = f"ğŸ” ê·œì¹™ ì˜¤ì—¼ ê²€ì‚¬ ê²°ê³¼\\n\\n"
            result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {project_name}\\n"
            result_text += f"ğŸ¯ ìƒíƒœ: {contamination_result['status']}\\n"
            result_text += f"ğŸš¨ ì˜¤ì—¼ ë°œê²¬: {'ì˜ˆ' if contamination_result['contamination_found'] else 'ì•„ë‹ˆì˜¤'}\\n\\n"
            
            if contamination_result['contamination_found']:
                result_text += f"ğŸ” ë°œê²¬ëœ ì˜¤ì—¼:\\n"
                for contamination in contamination_result['contaminated_rules']:
                    result_text += f"  â€¢ íƒ€ì…: {contamination['contamination_type']}\\n"
                    result_text += f"    ìœ ì‚¬ë„: {contamination['similarity']:.2f}\\n"
                    result_text += f"    í”„ë¡œì íŠ¸ ê·œì¹™: {contamination['project_rule']}\\n"
                    if contamination['global_rule']:
                        result_text += f"    ì „ì—­ ê·œì¹™: {contamination['global_rule']}\\n"
                    result_text += "\\n"
                
                result_text += f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: {contamination_result['recommendation']}\\n"
            else:
                result_text += "âœ… í”„ë¡œì íŠ¸ ê·œì¹™ì´ ê¹”ë”í•˜ê²Œ ë¶„ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\n"
                result_text += "ğŸ›¡ï¸ ì „ì—­ ê·œì¹™ ì˜¤ì—¼ ì—†ìŒ\\n"
            
        except Exception as e:
            result_text = f"âŒ ì˜¤ì—¼ ê²€ì‚¬ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def add_rule_with_isolation_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ê·œì¹™ ì¶”ê°€ (ì˜¤ì—¼ ë°©ì§€ ê²€ì‚¬ í¬í•¨)"""
        content = args["content"]
        rule_type_str = args["rule_type"]
        scope_str = args["scope"]
        project_name = args.get("project_name")
        source_context = args.get("source_context", "")
        
        try:
            # Enum ë³€í™˜
            rule_type_mapping = {
                "íŒ¨í„´": RuleType.PATTERN,
                "ê°€ì´ë“œë¼ì¸": RuleType.GUIDELINE,
                "ì„ í˜¸ë„": RuleType.PREFERENCE,
                "ì œì•½ì¡°ê±´": RuleType.CONSTRAINT,
                "ì›Œí¬í”Œë¡œìš°": RuleType.WORKFLOW
            }
            
            scope_mapping = {
                "ì „ì—­": RuleScope.GLOBAL,
                "í”„ë¡œì íŠ¸": RuleScope.PROJECT,
                "ì„¸ì…˜": RuleScope.SESSION,
                "ì„ì‹œ": RuleScope.TEMPORARY
            }
            
            rule_type = rule_type_mapping.get(rule_type_str)
            scope = scope_mapping.get(scope_str)
            
            if not rule_type or not scope:
                result_text = f"âŒ ì˜ëª»ëœ ê·œì¹™ íƒ€ì… ë˜ëŠ” ë²”ìœ„\\n"
                result_text += f"ê·œì¹™ íƒ€ì…: {rule_type_str}\\n"
                result_text += f"ë²”ìœ„: {scope_str}\\n"
            else:
                rule_id = self.rule_isolation.add_rule(
                    content, rule_type, scope, project_name, source_context
                )
                
                result_text = f"âœ… ê·œì¹™ ì¶”ê°€ ì™„ë£Œ\\n\\n"
                result_text += f"ğŸ†” ê·œì¹™ ID: {rule_id}\\n"
                result_text += f"ğŸ“ ë‚´ìš©: {content}\\n"
                result_text += f"ğŸ·ï¸ íƒ€ì…: {rule_type_str}\\n"
                result_text += f"ğŸ¯ ë²”ìœ„: {scope_str}\\n"
                
                if project_name:
                    result_text += f"ğŸ“‹ í”„ë¡œì íŠ¸: {project_name}\\n"
                
                # ì˜¤ì—¼ ë°©ì§€ ê²€ì‚¬ ê²°ê³¼ í‘œì‹œ
                if scope == RuleScope.GLOBAL:
                    result_text += "\\nğŸ›¡ï¸ ì „ì—­ ê·œì¹™ ì˜¤ì—¼ ë°©ì§€ ê²€ì‚¬ í†µê³¼\\n"
                else:
                    result_text += "\\nğŸ”’ í”„ë¡œì íŠ¸ ê·œì¹™ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ê²©ë¦¬ë¨\\n"
            
        except Exception as e:
            result_text = f"âŒ ê·œì¹™ ì¶”ê°€ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    # === í„°ë¯¸ë„ ì„¸ì…˜ ì¶”ì  ë„êµ¬ êµ¬í˜„ ===
    async def get_terminal_session_info_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í˜„ì¬ í„°ë¯¸ë„ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
        try:
            session_uptime = time.time() - self.session_start_time.timestamp()
            
            result_text = f"ğŸ–¥ï¸ í„°ë¯¸ë„ ì„¸ì…˜ ì •ë³´\\n\\n"
            result_text += f"ğŸ†” í„°ë¯¸ë„ ID: {self.terminal_id}\\n"
            result_text += f"â° ì„¸ì…˜ ì‹œì‘: {self.session_start_time.strftime('%Y-%m-%d %H:%M:%S')}\\n"
            result_text += f"â±ï¸ ì„¸ì…˜ ì§€ì†ì‹œê°„: {int(session_uptime//3600):02d}:{int((session_uptime%3600)//60):02d}:{int(session_uptime%60):02d}\\n"
            result_text += f"ğŸ’¬ ì´ ëŒ€í™” ìˆ˜: {self.conversation_counter}ê°œ\\n"
            result_text += f"âš™ï¸ ì´ ì‘ì—… ìˆ˜: {self.task_counter}ê°œ\\n\\n"
            
            result_text += f"ğŸ“‚ ì‘ì—… ê³µê°„: {self.workspace}\\n"
            result_text += f"ğŸ—„ï¸ ì„¸ì…˜ DB: {self.session_db_path.name}\\n"
            result_text += f"ğŸ“Š ë²„ì „: {self.version}\\n\\n"
            
            # ìµœê·¼ í™œë™
            try:
                with sqlite3.connect(str(self.session_db_path)) as conn:
                    cursor = conn.execute('''
                        SELECT COUNT(*) FROM conversations 
                        WHERE terminal_id = ? AND timestamp > ?
                    ''', (self.terminal_id, (datetime.now(timezone.utc) - timedelta(hours=1)).isoformat()))
                    
                    recent_count = cursor.fetchone()[0]
                    result_text += f"ğŸ“ˆ ìµœê·¼ 1ì‹œê°„ í™œë™: {recent_count}ê°œ ëŒ€í™”\\n"
                    
            except Exception as e:
                result_text += f"âŒ ìµœê·¼ í™œë™ ì¡°íšŒ ì‹¤íŒ¨: {e}\\n"
            
        except Exception as e:
            result_text = f"âŒ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def search_conversation_history_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™” ë‚´ì—­ ê²€ìƒ‰"""
        query = args["query"]
        time_range_hours = args.get("time_range_hours", 24)
        limit = args.get("limit", 10)
        
        try:
            search_time = (datetime.now(timezone.utc) - timedelta(hours=time_range_hours)).isoformat()
            
            with sqlite3.connect(str(self.session_db_path)) as conn:
                cursor = conn.execute('''
                    SELECT conversation_id, timestamp, request_data, response_data, status
                    FROM conversations 
                    WHERE terminal_id = ? AND timestamp > ?
                    AND (request_data LIKE ? OR response_data LIKE ?)
                    ORDER BY timestamp DESC LIMIT ?
                ''', (self.terminal_id, search_time, f"%{query}%", f"%{query}%", limit))
                
                results = cursor.fetchall()
            
            result_text = f"ğŸ” ëŒ€í™” ë‚´ì—­ ê²€ìƒ‰ ê²°ê³¼\\n\\n"
            result_text += f"ğŸ” ê²€ìƒ‰ì–´: {query}\\n"
            result_text += f"â° ê²€ìƒ‰ ë²”ìœ„: ìµœê·¼ {time_range_hours}ì‹œê°„\\n"
            result_text += f"ğŸ“Š ë°œê²¬ëœ ëŒ€í™”: {len(results)}ê°œ\\n\\n"
            
            if results:
                for i, (conv_id, timestamp, request_data, response_data, status) in enumerate(results, 1):
                    try:
                        request = json.loads(request_data)
                        method = request.get("method", "unknown")
                        
                        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                        time_str = dt.strftime('%m-%d %H:%M')
                        
                        result_text += f"{i}. [{time_str}] {conv_id}\\n"
                        result_text += f"   ë©”ì„œë“œ: {method} | ìƒíƒœ: {status}\\n"
                        
                        if method == "tools/call":
                            tool_name = request.get("params", {}).get("name", "unknown")
                            result_text += f"   ë„êµ¬: {tool_name}\\n"
                        
                        result_text += "\\n"
                        
                    except Exception as e:
                        result_text += f"{i}. íŒŒì‹± ì˜¤ë¥˜: {e}\\n\\n"
            else:
                result_text += "âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\\n"
            
        except Exception as e:
            result_text = f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def get_task_history_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì‘ì—… ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ"""
        task_type = args.get("task_type")
        status = args.get("status")
        limit = args.get("limit", 20)
        
        try:
            query = '''
                SELECT task_id, created_at, task_type, status, progress_data
                FROM task_tracking 
                WHERE terminal_id = ?
            '''
            params = [self.terminal_id]
            
            if task_type:
                query += " AND task_type = ?"
                params.append(task_type)
                
            if status:
                query += " AND status = ?"
                params.append(status)
                
            query += " ORDER BY created_at DESC LIMIT ?"
            params.append(limit)
            
            with sqlite3.connect(str(self.session_db_path)) as conn:
                cursor = conn.execute(query, params)
                results = cursor.fetchall()
            
            result_text = f"âš™ï¸ ì‘ì—… ì‹¤í–‰ ì´ë ¥\\n\\n"
            result_text += f"ğŸ“Š ì¡°íšŒëœ ì‘ì—…: {len(results)}ê°œ\\n"
            if task_type:
                result_text += f"ğŸ¯ ì‘ì—… íƒ€ì…: {task_type}\\n"
            if status:
                result_text += f"ğŸ“‹ ìƒíƒœ: {status}\\n"
            result_text += "\\n"
            
            if results:
                for i, (task_id, created_at, ttype, tstatus, progress_data) in enumerate(results, 1):
                    try:
                        dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                        time_str = dt.strftime('%m-%d %H:%M:%S')
                        
                        result_text += f"{i}. [{time_str}] {task_id}\\n"
                        result_text += f"   íƒ€ì…: {ttype} | ìƒíƒœ: {tstatus}\\n"
                        
                        if progress_data:
                            try:
                                progress = json.loads(progress_data)
                                if "response_time" in progress:
                                    result_text += f"   ì‹¤í–‰ì‹œê°„: {progress['response_time']:.3f}ì´ˆ\\n"
                            except:
                                pass
                        
                        result_text += "\\n"
                        
                    except Exception as e:
                        result_text += f"{i}. íŒŒì‹± ì˜¤ë¥˜: {e}\\n\\n"
            else:
                result_text += "âŒ ì‘ì—… ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.\\n"
            
        except Exception as e:
            result_text = f"âŒ ì‘ì—… ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def restore_previous_context_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """ì´ì „ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë³µì›"""
        hours_back = args.get("hours_back", 24)
        
        try:
            search_time = (datetime.now(timezone.utc) - timedelta(hours=hours_back)).isoformat()
            
            with sqlite3.connect(str(self.session_db_path)) as conn:
                cursor = conn.execute('''
                    SELECT context_data, metadata, snapshot_time
                    FROM context_snapshots 
                    WHERE terminal_id = ? AND snapshot_time > ?
                    ORDER BY snapshot_time DESC LIMIT 1
                ''', (self.terminal_id, search_time))
                
                result = cursor.fetchone()
            
            if result:
                context_data, metadata_str, snapshot_time = result
                
                try:
                    restored_context = pickle.loads(context_data)
                    metadata = json.loads(metadata_str)
                    
                    # ì»¨í…ìŠ¤íŠ¸ ë³µì›
                    if "context_memory" in restored_context:
                        self.context_memory.update(restored_context["context_memory"])
                    
                    if "conversation_count" in restored_context:
                        self.conversation_counter = max(self.conversation_counter, restored_context["conversation_count"])
                    
                    if "task_count" in restored_context:
                        self.task_counter = max(self.task_counter, restored_context["task_count"])
                    
                    result_text = f"ğŸ”„ ì»¨í…ìŠ¤íŠ¸ ë³µì› ì™„ë£Œ\\n\\n"
                    result_text += f"ğŸ“… ë³µì› ì‹œì : {snapshot_time[:19].replace('T', ' ')}\\n"
                    result_text += f"ğŸ’¾ ë³µì›ëœ ë©”ëª¨ë¦¬: {len(self.context_memory)}ê°œ í•­ëª©\\n"
                    result_text += f"ğŸ’¬ ëŒ€í™” ì¹´ìš´í„°: {self.conversation_counter}\\n"
                    result_text += f"âš™ï¸ ì‘ì—… ì¹´ìš´í„°: {self.task_counter}\\n"
                    result_text += f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata.get('snapshot_type', 'unknown')}\\n"
                    
                except Exception as e:
                    result_text = f"âŒ ì»¨í…ìŠ¤íŠ¸ ë³µì› ì‹¤íŒ¨\\n\\në°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}"
            else:
                result_text = f"âŒ ë³µì›í•  ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ\\n\\n"
                result_text += f"â° ê²€ìƒ‰ ë²”ìœ„: ìµœê·¼ {hours_back}ì‹œê°„\\n"
                result_text += f"ğŸ’¡ ë” ë„“ì€ ë²”ìœ„ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.\\n"
            
        except Exception as e:
            result_text = f"âŒ ì»¨í…ìŠ¤íŠ¸ ë³µì› ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def get_session_statistics_tool(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """í„°ë¯¸ë„ ì„¸ì…˜ í†µê³„ ì •ë³´"""
        include_performance = args.get("include_performance", True)
        
        try:
            with sqlite3.connect(str(self.session_db_path)) as conn:
                # ì „ì²´ í†µê³„
                cursor = conn.execute('''
                    SELECT COUNT(*), MIN(timestamp), MAX(timestamp)
                    FROM conversations WHERE terminal_id = ?
                ''', (self.terminal_id,))
                total_conversations, min_time, max_time = cursor.fetchone()
                
                # ìƒíƒœë³„ í†µê³„
                cursor = conn.execute('''
                    SELECT status, COUNT(*) FROM conversations 
                    WHERE terminal_id = ? GROUP BY status
                ''', (self.terminal_id,))
                status_stats = dict(cursor.fetchall())
                
                # ìµœê·¼ 24ì‹œê°„ í™œë™
                recent_time = (datetime.now(timezone.utc) - timedelta(hours=24)).isoformat()
                cursor = conn.execute('''
                    SELECT COUNT(*) FROM conversations 
                    WHERE terminal_id = ? AND timestamp > ?
                ''', (self.terminal_id, recent_time))
                recent_activity = cursor.fetchone()[0]
                
                # ì‘ì—… íƒ€ì…ë³„ í†µê³„
                cursor = conn.execute('''
                    SELECT task_type, COUNT(*) FROM task_tracking 
                    WHERE terminal_id = ? GROUP BY task_type
                ''', (self.terminal_id,))
                task_type_stats = dict(cursor.fetchall())
            
            result_text = f"ğŸ“Š í„°ë¯¸ë„ ì„¸ì…˜ í†µê³„\\n\\n"
            result_text += f"ğŸ†” í„°ë¯¸ë„ ID: {self.terminal_id}\\n\\n"
            
            # ê¸°ë³¸ í†µê³„
            result_text += f"ğŸ“ˆ ì „ì²´ í†µê³„:\\n"
            result_text += f"  â€¢ ì´ ëŒ€í™” ìˆ˜: {total_conversations}ê°œ\\n"
            result_text += f"  â€¢ ìµœê·¼ 24ì‹œê°„: {recent_activity}ê°œ\\n"
            result_text += f"  â€¢ í˜„ì¬ ì„¸ì…˜: {self.conversation_counter}ê°œ\\n\\n"
            
            # ìƒíƒœë³„ í†µê³„
            if status_stats:
                result_text += f"ğŸ“‹ ìƒíƒœë³„ í†µê³„:\\n"
                for status, count in status_stats.items():
                    percentage = (count / total_conversations * 100) if total_conversations > 0 else 0
                    result_text += f"  â€¢ {status}: {count}ê°œ ({percentage:.1f}%)\\n"
                result_text += "\\n"
            
            # ì‘ì—… íƒ€ì…ë³„ í†µê³„
            if task_type_stats:
                result_text += f"âš™ï¸ ì‘ì—… íƒ€ì…ë³„ í†µê³„:\\n"
                for task_type, count in list(task_type_stats.items())[:10]:  # ìƒìœ„ 10ê°œë§Œ
                    result_text += f"  â€¢ {task_type}: {count}ê°œ\\n"
                result_text += "\\n"
            
            # ì„±ëŠ¥ ì •ë³´
            if include_performance:
                result_text += f"ğŸš€ ì„±ëŠ¥ ë©”íŠ¸ë¦­:\\n"
                result_text += f"  â€¢ í‰ê·  ì‘ë‹µì‹œê°„: {self.performance_metrics['average_response_time']:.3f}ì´ˆ\\n"
                result_text += f"  â€¢ ì´ ìš”ì²­: {self.performance_metrics['total_requests']}ê°œ\\n"
                result_text += f"  â€¢ ì„±ê³µ ì‘ì—…: {self.performance_metrics['successful_operations']}ê°œ\\n"
                result_text += f"  â€¢ ì°¨ë‹¨ ì‘ì—…: {self.performance_metrics['blocked_operations']}ê°œ\\n"
                
                if self.performance_metrics['total_requests'] > 0:
                    success_rate = self.performance_metrics['successful_operations'] / self.performance_metrics['total_requests'] * 100
                    result_text += f"  â€¢ ì„±ê³µë¥ : {success_rate:.1f}%\\n"
            
            # ì„¸ì…˜ ì‹œê°„ ì •ë³´
            if min_time and max_time:
                session_duration = (datetime.fromisoformat(max_time.replace('Z', '+00:00')) - 
                                  datetime.fromisoformat(min_time.replace('Z', '+00:00'))).total_seconds()
                hours = int(session_duration // 3600)
                minutes = int((session_duration % 3600) // 60)
                result_text += f"\\nâ° í™œë™ ê¸°ê°„:\\n"
                result_text += f"  â€¢ ì²« í™œë™: {min_time[:19].replace('T', ' ')}\\n"
                result_text += f"  â€¢ ë§ˆì§€ë§‰: {max_time[:19].replace('T', ' ')}\\n"
                result_text += f"  â€¢ ì´ ê¸°ê°„: {hours}ì‹œê°„ {minutes}ë¶„\\n"
            
        except Exception as e:
            result_text = f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨\\n\\nì˜¤ë¥˜: {str(e)}"
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result_text
                }
            ]
        }

    async def list_resources(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ ëª©ë¡"""
        resources = [
            {
                "uri": "system://health",
                "name": "ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ",
                "description": "BOOSAAN ULTIMATE ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ",
                "mimeType": "application/json"
            },
            {
                "uri": "system://performance",
                "name": "ì„±ëŠ¥ ë©”íŠ¸ë¦­",
                "description": "ì‹œìŠ¤í…œ ì„±ëŠ¥ ë° ì‚¬ìš© í†µê³„",
                "mimeType": "application/json"
            },
            {
                "uri": "context://summary",
                "name": "ë§¥ë½ ìš”ì•½",
                "description": "ì „ì²´ ë§¥ë½ ê´€ë¦¬ ì‹œìŠ¤í…œ ìš”ì•½",
                "mimeType": "application/json"
            },
            {
                "uri": "sandbox://list",
                "name": "ìƒŒë“œë°•ìŠ¤ ëª©ë¡",
                "description": "í™œì„± ìƒŒë“œë°•ìŠ¤ ëª©ë¡ ë° ìƒíƒœ",
                "mimeType": "application/json"
            }
        ]
        
        return {"resources": resources}

    async def read_resource(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """ë¦¬ì†ŒìŠ¤ ì½ê¸°"""
        uri = params.get("uri", "")
        
        if uri == "system://health":
            health_data = await self.system_health_check({"detailed": True})
            content = health_data["content"][0]["text"]
        elif uri == "system://performance":
            perf_data = await self.performance_metrics_tool({})
            content = perf_data["content"][0]["text"]
        elif uri == "context://summary":
            summary = self.context_manager.get_context_summary()
            content = json.dumps(summary, ensure_ascii=False, indent=2)
        elif uri == "sandbox://list":
            sandbox_list = self.sandbox_manager.list_sandboxes()
            content = json.dumps(sandbox_list, ensure_ascii=False, indent=2)
        else:
            return {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ë¦¬ì†ŒìŠ¤: {uri}"}
        
        return {
            "contents": [
                {
                    "uri": uri,
                    "mimeType": "text/plain",
                    "text": content
                }
            ]
        }

    def _update_performance_metrics(self, response_time: float, success: bool):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        # ì´ë™ í‰ê· ìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        current_avg = self.performance_metrics["average_response_time"]
        total_requests = self.performance_metrics["total_requests"]
        
        if total_requests > 1:
            new_avg = ((current_avg * (total_requests - 1)) + response_time) / total_requests
        else:
            new_avg = response_time
        
        self.performance_metrics["average_response_time"] = new_avg

async def main():
    """MCP ì„œë²„ ì‹¤í–‰"""
    server = BOOSAANUltimateMCPServer()
    
    # stdioë¡œ MCP í”„ë¡œí† ì½œ ì²˜ë¦¬ (ì•ˆì „ ì¢…ë£Œ ì¶”ê°€)
    logger = logging.getLogger(__name__)
    logger.info("BOOSAAN MCP ì„œë²„ ì‹œì‘")
    
    try:
        while True:
            try:
                line = await asyncio.to_thread(sys.stdin.readline)
                if not line:
                    logger.info("stdin ì¢…ë£Œ, ì„œë²„ ì¢…ë£Œ")
                    break
                    
                request = json.loads(line.strip())
                response = await server.handle_request(request)
                
                print(json.dumps(response))
                sys.stdout.flush()
                
            except KeyboardInterrupt:
                logger.info("í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œ")
                break
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
            except Exception as e:
                logger.error(f"ìš”ì²­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                error_response = {
                    "jsonrpc": "2.0",
                    "id": None,
                    "error": {
                        "code": -32603,
                        "message": str(e)
                    }
                }
                print(json.dumps(error_response))
                sys.stdout.flush()
    except Exception as e:
        logger.error(f"ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    finally:
        logger.info("BOOSAAN MCP ì„œë²„ ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())